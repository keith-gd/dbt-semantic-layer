# dbt Developer Hub

> End user documentation, guides and technical reference for dbt

- [The dbt Developer Hub](https://docs.getdbt.com/index.md)


## API Reference

- [About the Discovery API schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-about.md): With the Discovery API, you can query the metadata in dbt to learn more about your dbt deployments and the data they generate. You can analyze the data to make improvements. If you are new to the API, refer to About the Discovery API for an introduction. You might also find the use cases and examples helpful.
- [About the Discovery API StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-api.md): Every time  runs a project, it generates and stores information about the project. The metadata includes details about your project’s models, sources, and other nodes along with their execution results. With the  Discovery API, you can query this comprehensive information to gain a better understanding of your DAG and the data it produces.
- [Account-scoped personal access tokens](https://docs.getdbt.com/docs/dbt-cloud-apis/user-tokens.md): User API tokens have been deprecated and will no longer work. Migrate to personal access tokens to resume services.
- [APIs overview StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/dbt-cloud-apis/overview.md): Learn how dbt accounts on the Enterprise-tier plans can query the dbt APIs.
- [Applied object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-environment-applied.md): The applied object allows you to query information about a particular model based on environmentId.
- [Authentication tokens](https://docs.getdbt.com/docs/dbt-cloud-apis/authentication.md): Learn how to authenticate with user tokens and service account tokens 
- [dbt Administrative API StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/dbt-cloud-apis/admin-cloud-api.md): The  Administrative API is enabled by default for Enterprise and Enterprise+ plans. It can be used to:
- [Definition object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-environment-definition.md): The definition object allows you to query the logical state of a given project node given its most recent manifest generated models.
- [Environment object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-environment.md): You can use the environment object to query and compare definition (intended) and applied (actual) states for nodes (models, seeds, snapshots, models, and more) in your dbt project.  For example, you specify an environmentId to learn more about a particular model (or other node type) in that environment.
- [Exposure object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-job-exposure.md): The exposure object allows you to query information about a particular exposure. To learn more, refer to Add Exposures to your DAG.
- [Exposure Tile object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-environment-applied-exposure-tile.md): Exposure health tiles distill data health signals for data consumers and can be embedded in downstream tools. You can query information on these tiles from the Discovery API.
- [Exposures object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-environment-applied-exposures.md): Exposures are dbt resources that represent downstream uses of your project, such as dashboards, applications, or data science pipelines. You can query exposures through the Discovery API to understand which assets depend on your models.
- [Exposures object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-job-exposures.md): The exposures object allows you to query information about all exposures in a given job. To learn more, refer to Add Exposures to your DAG.
- [GraphQL StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/dbt-cloud-apis/sl-graphql.md): Integrate and use the GraphQL API to query your metrics.
- [JDBC API StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/dbt-cloud-apis/sl-jdbc.md): Integrate and use the JDBC API to query your metrics.
- [Job object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-job.md): The job object allows you to query information about a particular model based on jobId and, optionally, a runId.
- [Lineage object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-environment-applied-lineage.md): The lineage object allows you to query lineage across your resources.
- [Model Historical Runs object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-environment-applied-modelHistoricalRuns.md): The model historical runs object allows you to query information about a model's run history.
- [Model object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-job-model.md): The model object allows you to query information about a particular model in a given job.
- [Models object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-environment-applied-models.md): Models are the foundational dbt resource that transform raw data into curated datasets using SQL (or Python). Each model represents a single SELECT statement, typically materialized as a table or view in your warehouse. You can query information about models through the Discovery API.
- [Models object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-job-models.md): The models object allows you to query information about all models in a given job.
- [Owners object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-environment-applied-owners.md): Owners help you identify the user or domain responsible for a dbt asset. For most assets, owners are defined in your project code using groups. Exposures are an exception: for downstream exposures that represent BI assets, owners are automatically pulled from the downstream tool based on who owns that asset. You can query ownership information through the Discovery API.
- [Packages object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-environment-applied-packages.md): dbt packages are libraries with models, macros, and other resources that tackle a specific problem area utilized by dbt projects. You can query project packages through the Discovery API.
- [Project state in dbt](https://docs.getdbt.com/docs/dbt-cloud-apis/project-state.md): provides a stateful way of deploying dbt. Artifacts are accessible programmatically via the Discovery API in the metadata platform.
- [Python SDK StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/dbt-cloud-apis/sl-python.md): Learn how to use the dbt Semantic Layer Python SDK library to interact with the dbt Semantic Layer.
- [Query the Discovery API](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-querying.md): The Discovery API supports ad-hoc queries and integrations. If you are new to the API, refer to About the Discovery API for an introduction.
- [Resources object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-environment-applied-resources.md): The resources object allows you to paginate across all resources in your environment.
- [Seed object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-job-seed.md): The seed object allows you to query information about a particular seed in a given job.
- [Seeds object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-environment-applied-seeds.md): Seeds are CSV files in your dbt project that dbt can load into your data warehouse. You can query seeds through the Discovery API.
- [Seeds object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-job-seeds.md): The seeds object allows you to query information about all seeds in a given job.
- [Semantic Layer APIs StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/dbt-cloud-apis/sl-api-overview.md): Integrate and query metrics and dimensions in downstream tools using the Semantic Layer APIs
- [Service account tokens StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/dbt-cloud-apis/service-tokens.md): Service account tokens help you define permissions for securing access to your dbt account and its projects.
- [Snapshots object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-environment-applied-snapshots.md): Snapshots represent point-in-time copies of your data, allowing you to track historical changes. You can query your snapshots from the Discovery API.
- [Snapshots object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-job-snapshots.md): The snapshots object allows you to query information about all snapshots in a given job.
- [Source object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-job-source.md): The source object allows you to query information about a particular source in a given job.
- [Sources object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-environment-applied-sources.md): Sources make it possible to name and describe the data loaded into your warehouse by your extract and load tools. You can query sources through the Discovery API.
- [Sources object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-job-sources.md): The sources object allows you to query information about all sources in a given job.
- [Tags object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-environment-applied-tags.md): Tags provide a mechanism to categorize and group resources within a dbt project, enabling selective execution and management of these resources. You can query tags through the Discovery API.
- [Test object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-job-test.md): The test object allows you to query information about a particular test.
- [Tests object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-environment-applied-tests.md): Tests are assertions you make about your models and other resources in your dbt project. When you run dbt test, dbt will tell you if each test in your project passes or fails. You can query tests through the Discovery API to understand information about them.
- [Tests object schema](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-schema-job-tests.md): The tests object allows you to query information about all tests in a given job.
- [Use cases and examples for the Discovery API](https://docs.getdbt.com/docs/dbt-cloud-apis/discovery-use-cases-and-examples.md): With the Discovery API, you can query the metadata in  to learn more about your dbt deployments and the data it generates to analyze them and make improvements.

## Best Practices

- [Available materializations](https://docs.getdbt.com/best-practices/materializations/2-available-materializations.md): Read this guide to understand the different types of materializations you can create in dbt.
- [Best practice guides](https://docs.getdbt.com/best-practices.md): Learn how dbt Labs approaches building projects through our current viewpoints on structure, style, and setup.
- [Best practices](https://docs.getdbt.com/best-practices/how-we-build-our-metrics/semantic-layer-9-conclusion.md): Getting started with the dbt Semantic Layer
- [Best practices for dbt and Unity Catalog](https://docs.getdbt.com/best-practices/dbt-unity-catalog-best-practices.md): Learn how to configure your.
- [Best practices for materializations](https://docs.getdbt.com/best-practices/materializations/5-best-practices.md): Read this guide to understand the different types of materializations you can create in dbt.
- [Best practices for workflows](https://docs.getdbt.com/best-practices/best-practice-workflows.md): This page contains the collective wisdom of experienced users of dbt on how to best use it in your analytics work. Observing these best practices will help your analytics team work as effectively as possible, while implementing the pro-tips will add some polish to your dbt projects!
- [Building metrics](https://docs.getdbt.com/best-practices/how-we-build-our-metrics/semantic-layer-4-build-metrics.md): Getting started with the dbt Semantic Layer
- [Building semantic models](https://docs.getdbt.com/best-practices/how-we-build-our-metrics/semantic-layer-3-build-semantic-models.md): Getting started with the dbt Semantic Layer
- [Clone incremental models as the first step of your CI job](https://docs.getdbt.com/best-practices/clone-incremental-models.md): Learn how to define clone incremental models as the first step of your CI job.
- [Conclusion](https://docs.getdbt.com/best-practices/materializations/7-conclusion.md): Read this conclusion to our guide on using materializations in dbt and how it is a crucial skill for effective analytics engineering.
- [Configuring materializations](https://docs.getdbt.com/best-practices/materializations/3-configuring-materializations.md): Read this guide to understand how to configure materializations in dbt.
- [dbt Mesh FAQs](https://docs.getdbt.com/best-practices/how-we-mesh/mesh-5-faqs.md): Read the FAQs to learn more about dbt Mesh, how it works, compatibility, and more.
- [Deciding how to structure your dbt Mesh](https://docs.getdbt.com/best-practices/how-we-mesh/mesh-3-structures.md): Getting started with dbt Mesh patterns
- [Don't nest your curlies](https://docs.getdbt.com/best-practices/dont-nest-your-curlies.md): Poetry
- [Examining our builds](https://docs.getdbt.com/best-practices/materializations/6-examining-builds.md): Read this guide to understand how to examine your builds in dbt.
- [How we structure our dbt projects](https://docs.getdbt.com/best-practices/how-we-structure/1-guide-overview.md): Learn how we structure our dbt projects.
- [How we style our dbt models](https://docs.getdbt.com/best-practices/how-we-style/1-how-we-style-our-dbt-models.md): Fields and model names
- [How we style our dbt projects](https://docs.getdbt.com/best-practices/how-we-style/0-how-we-style-our-dbt-projects.md): Why does style matter?
- [How we style our Jinja](https://docs.getdbt.com/best-practices/how-we-style/4-how-we-style-our-jinja.md): Jinja style guide
- [How we style our Python](https://docs.getdbt.com/best-practices/how-we-style/3-how-we-style-our-python.md): Python tooling
- [How we style our SQL](https://docs.getdbt.com/best-practices/how-we-style/2-how-we-style-our-sql.md): Basics
- [How we style our YAML](https://docs.getdbt.com/best-practices/how-we-style/5-how-we-style-our-yaml.md): YAML Style Guide
- [Implementing your mesh plan](https://docs.getdbt.com/best-practices/how-we-mesh/mesh-4-implementation.md): Getting started with dbt Mesh patterns
- [Incremental models in-depth](https://docs.getdbt.com/best-practices/materializations/4-incremental-models.md): Read this guide to understand the incremental models you can create in dbt.
- [Intermediate: Purpose-built transformation steps](https://docs.getdbt.com/best-practices/how-we-structure/3-intermediate.md): Purpose-built transformation steps.
- [Intro to dbt Mesh](https://docs.getdbt.com/best-practices/how-we-mesh/mesh-1-intro.md): Getting started with dbt Mesh patterns
- [Intro to the dbt Semantic Layer](https://docs.getdbt.com/best-practices/how-we-build-our-metrics/semantic-layer-1-intro.md): Getting started with the dbt Semantic Layer
- [Marts: Business-defined entities](https://docs.getdbt.com/best-practices/how-we-structure/4-marts.md): Our guidance here diverges if you use the . In a project without the  we recommend you denormalize heavily, per the best practices below. On the other hand, if you're using the , we want to stay as normalized as possible to allow MetricFlow the most flexibility. See The dbt Semantic Layer and marts for more information.
- [Materializations best practices](https://docs.getdbt.com/best-practices/materializations/1-guide-overview.md): Read this guide to understand how using materializations in dbt is a crucial skill for effective analytics engineering.
- [More advanced metrics](https://docs.getdbt.com/best-practices/how-we-build-our-metrics/semantic-layer-5-advanced-metrics.md): Getting started with the dbt Semantic Layer
- [Now it's your turn](https://docs.getdbt.com/best-practices/how-we-style/6-how-we-style-conclusion.md): BYO Styles
- [Refactor an existing rollup](https://docs.getdbt.com/best-practices/how-we-build-our-metrics/semantic-layer-8-refactor-a-rollup.md): Getting started with the dbt Semantic Layer
- [Semantic structure](https://docs.getdbt.com/best-practices/how-we-build-our-metrics/semantic-layer-7-semantic-structure.md): Getting started with the dbt Semantic Layer
- [Set up the dbt Semantic Layer](https://docs.getdbt.com/best-practices/how-we-build-our-metrics/semantic-layer-2-setup.md): Getting started with the dbt Semantic Layer
- [Staging: Preparing our atomic building blocks](https://docs.getdbt.com/best-practices/how-we-structure/2-staging.md): Preparing our atomic building blocks.
- [Tactical terminology](https://docs.getdbt.com/best-practices/how-we-build-our-metrics/semantic-layer-6-terminology.md): Getting started with the dbt Semantic Layer
- [The rest of the project](https://docs.getdbt.com/best-practices/how-we-structure/5-the-rest-of-the-project.md): The rest of the project.
- [Who is dbt Mesh for?](https://docs.getdbt.com/best-practices/how-we-mesh/mesh-2-who-is-dbt-mesh-for.md): Understanding if dbt Mesh is the right fit for your team
- [Writing custom generic data tests](https://docs.getdbt.com/best-practices/writing-custom-generic-tests.md): Learn how to define your own custom generic data tests.

## Category

- [Account FAQs](https://docs.getdbt.com/category/accounts.md)
- [Available flags](https://docs.getdbt.com/category/available-flags.md): The list of flags available in dbt.
- [dbt Core FAQs](https://docs.getdbt.com/category/dbt-core.md)
- [Documentation FAQs](https://docs.getdbt.com/category/documentation.md)
- [Environments FAQs](https://docs.getdbt.com/category/environments.md)
- [General configs](https://docs.getdbt.com/category/general-configs.md): The list of general configs available in dbt.
- [General properties](https://docs.getdbt.com/category/general-properties.md): The list of general properties available in dbt.
- [Git FAQs](https://docs.getdbt.com/category/git.md)
- [Jinja FAQs](https://docs.getdbt.com/category/jinja.md)
- [Jinja reference](https://docs.getdbt.com/category/jinja-reference.md): The list of Jinja functions available in dbt.
- [List of commands](https://docs.getdbt.com/category/list-of-commands.md): The list of commands available in dbt.
- [Models FAQs](https://docs.getdbt.com/category/models.md)
- [Project configs](https://docs.getdbt.com/category/project-configs.md): The list of project configs available in dbt.
- [Project FAQs](https://docs.getdbt.com/category/projects.md)
- [Runs FAQs](https://docs.getdbt.com/category/runs.md)
- [Seeds FAQs](https://docs.getdbt.com/category/seeds.md)
- [Setting flags](https://docs.getdbt.com/category/setting-flags.md): The flags you can set to configure dbt.
- [Snapshots FAQs](https://docs.getdbt.com/category/snapshots.md)
- [Tests FAQs](https://docs.getdbt.com/category/tests.md)
- [Troubleshooting FAQs](https://docs.getdbt.com/category/troubleshooting.md)
- [Warehouse FAQs](https://docs.getdbt.com/category/warehouse.md)

## Community

- [Alan Cruickshank](https://docs.getdbt.com/community/spotlight/alan-cruickshank.md): I've been around in the dbt community, especially the London dbt Meetup, since early 2019—around the time that we started using db...
- [Alison Stanton](https://docs.getdbt.com/community/spotlight/alison-stanton.md): I started programming 20+ years ago. I moved from web applications into transforming data and business intelligence reporting beca...
- [Anya Prosvetova](https://docs.getdbt.com/community/spotlight/anya-prosvetova.md): I’m a Data Engineer with a background in SaaS, consulting, financial services and the creative industries. I help organisations co...
- [Become a contributor](https://docs.getdbt.com/community/contribute.md): Want to get involved? Start here
- [Bruno de Lima](https://docs.getdbt.com/community/spotlight/bruno-de-lima.md): Hey all! I was born and raised in Florianopolis, Brazil, and I'm a Senior Data Engineer at phData. I live with my fiancée and I en...
- [Christophe Oudar](https://docs.getdbt.com/community/spotlight/christophe-oudar.md): I joined the dbt Community in November 2021 after exchanging some issues in Github. I currently work as a staff engineer at a scal...
- [Coding contributions](https://docs.getdbt.com/community/contributing/contributing-coding.md): Contribute to dbt Packages
- [Community Forum guidelines](https://docs.getdbt.com/community/resources/forum-guidelines.md): What is the dbt Community Forum?
- [Community spotlight](https://docs.getdbt.com/community/spotlight.md)
- [Contributor License Agreements](https://docs.getdbt.com/community/resources/contributor-license-agreements.md): Why we have a CLA
- [Dakota Kelley](https://docs.getdbt.com/community/spotlight/dakota-kelley.md): For the last ~2 years I've worked at phData. Before that I spent 8 years working as a Software Developer in the public sector. Cur...
- [David Effiong](https://docs.getdbt.com/community/spotlight/david-effiong.md): I started my career as a data analyst but I currently work as a data engineer in a financial Institution. I have experience workin...
- [dbt Community Code of Conduct](https://docs.getdbt.com/community/resources/code-of-conduct.md): Learn about the community values that shape our rules, and review our anti-harassment policy.
- [dbt Community Rules of the Road](https://docs.getdbt.com/community/resources/community-rules-of-the-road.md): This community is filled with smart, kind, and helpful people who share our commitment to elevating the analytics profession. These rules help everyone understand how to best participate.
- [dbt Labs Community #jobs Channels Terms and Conditions](https://docs.getdbt.com/community/resources/jobs-terms-and-conditions.md): Before posting a job in the dbt Community or submitting an application, review these terms and conditions.
- [Emily Riederer](https://docs.getdbt.com/community/spotlight/emily-riederer.md): I'm a long-time dbt user and have been an active community member for a few years. Professionally, I've led a variety of data te...
- [Expectations for dbt contributors](https://docs.getdbt.com/community/resources/contributor-expectations.md): Whether it's dbt-core, dbt-fusion, adapters, packages, or this very documentation site, contributing to the open source or source-available code that supports the dbt ecosystem is a great way to share your knowledge, level yourself up as a developer, and to give back to the community. The goal of this page is to help you understand what to expect when contributing to dbt ecosystem projects.
- [Faith Lierheimer](https://docs.getdbt.com/community/spotlight/faith-lierheimer.md): I've been a dbt Community member for around a year and a half. I come to the data world from teaching and academic research. Worki...
- [Getting help](https://docs.getdbt.com/community/resources/getting-help.md): Community help
- [How to deliver a fantastic meetup talk](https://docs.getdbt.com/community/resources/speaking-at-a-meetup.md): Speaking at a dbt meetup? Here’s all the details you’ll need to know. If you’re speaking at another event, check out our additional tips at the end of the article.
- [Jenna Jordan](https://docs.getdbt.com/community/spotlight/jenna-jordan.md): I am a Senior Data Management Consultant with Analytics8, where I advise clients on dbt best practices (especially regarding dbt M...
- [Jing Yu Lim](https://docs.getdbt.com/community/spotlight/jing-yu-lim.md): For ~3 years, I was a Product Analyst at Grab, a ride-hailing and food delivery app in Southeast Asia, before taking on an Analyti...
- [Johann de Wet](https://docs.getdbt.com/community/spotlight/johann-de-wet.md): I'm forever indebted to my manager, John Pienaar, who introduced me to both dbt and it's community when I joined his team as an An...
- [Join the Community](https://docs.getdbt.com/community/join.md): Want to learn how organizations around the world are tackling the biggest challenges in data while making new friends from the best analytics teams? Join the dbt Community — data practitioners’ favorite place to learn new skills, keep on top of industry trends, and forge connections.
- [Josh Devlin](https://docs.getdbt.com/community/spotlight/josh-devlin.md): Josh Devlin has a rich history of community involvement and technical expertise in both the dbt and wider analytics communities....
- [Juan Manuel Perafan](https://docs.getdbt.com/community/spotlight/juan-manuel-perafan.md): Born and raised in Colombia! Living in the Netherlands since 2011. I've been working in the realm of analytics since 2017, focusin...
- [Karen Hsieh](https://docs.getdbt.com/community/spotlight/karen-hsieh.md): I’m a Product Manager who builds company-wide data literacy and empowers the product team to create values for people and grow the...
- [Maintaining a Slack channel](https://docs.getdbt.com/community/resources/maintaining-a-channel.md): There are three things you should do to be a good channel maintainer in the dbt Slack community
- [Mariah Rogers](https://docs.getdbt.com/community/spotlight/mariah-rogers.md): I got my start in the data world helping create a new major and minor in Data Science at my alma mater. I then became a data engin...
- [Meagan Palmer](https://docs.getdbt.com/community/spotlight/meagan-palmer.md): I first started using dbt in 2016 or 2017 (I can't remember exactly). Since then, I have moved into data and analytics consulting ...
- [Mike Stanley](https://docs.getdbt.com/community/spotlight/mike-stanley.md): I've split my time between financial services and the video games industry. Back when I wrote code every day, I worked in marketin...
- [Mikko Sulonen](https://docs.getdbt.com/community/spotlight/mikko-sulonen.md): I've been working with data since 2016. I first started with the on-prem SQL Server S-stack of SSIS, SSAS, SSRS. I did some QlikVi...
- [Oliver Cramer](https://docs.getdbt.com/community/spotlight/oliver-cramer.md): When I joined Aquila Capital in early 2022, I had the ModernDataStack with SqlDBM, dbt & Snowflake available. During the first hal...
- [Online community building](https://docs.getdbt.com/community/contributing/contributing-online-community.md): Maintaining a channel in the dbt Community Slack
- [Open source and source-available projects](https://docs.getdbt.com/community/resources/oss-sa-projects.md): Looking for a good place to get involved contributing code? dbt Labs supports the following repositories, organized by the language primarily needed for contribution:
- [Opeyemi Fabiyi](https://docs.getdbt.com/community/spotlight/fabiyi-opeyemi.md): I’m an Analytics Engineer with Data Culture, a Data Consulting firm where I use dbt  regularly to help clients build quality-teste...
- [Owen Prough](https://docs.getdbt.com/community/spotlight/owen-prough.md): Well met, data adventurer! My professional data history is mostly USA healthcare-related (shout out to ANSI X12 claim files) while...
- [Radovan Bacovic](https://docs.getdbt.com/community/spotlight/radovan-bacovic.md): My professional journey and friendship with data started 20 years ago.I've experienced many tools and modalities: from good old R...
- [Realtime event participation](https://docs.getdbt.com/community/contributing/contributing-realtime-events.md): Speak at a Meetup
- [Ruth Onyekwe](https://docs.getdbt.com/community/spotlight/ruth-onyekwe.md): I've been working in the world of Data Analytics for over 5 years and have been part of the dbt community for the last 4. With a b...
- [Safiyy Momen](https://docs.getdbt.com/community/spotlight/safiyy-momen.md): I've been in the dbt community for ~4 years now. My experience is primarily in leading data teams, previously at a healthcare star...
- [Sam Debruyn](https://docs.getdbt.com/community/spotlight/sam-debruyn.md): I have a background of about 10 years in software engineering and moved to data engineering in 2020. Today, I lead dataroots's dat...
- [Shinya Takimoto](https://docs.getdbt.com/community/spotlight/shinya-takimoto.md): I have about 3 years of dbt experience. I used to be in a large organization where the challenge was to create a quality analysis ...
- [Stacy Lo](https://docs.getdbt.com/community/spotlight/stacy-lo.md): I began my career as a data analyst, then transitioned to a few different roles in data and software development. Analytics Engine...
- [Sydney Burns](https://docs.getdbt.com/community/spotlight/sydney-burns.md): In 2019, I started as an analytics intern at a healthcare tech startup. I learned about dbt in 2020 and joined the community to se...
- [The dbt Viewpoint](https://docs.getdbt.com/community/resources/viewpoint.md): In 2015-2016, a team of folks at RJMetrics had the opportunity to observe, and participate in, a significant evolution of the analytics ecosystem. The seeds of dbt were conceived in this environment, and the viewpoint below was written to reflect what we had learned and how we believed the world should be different. dbt is our attempt to address the workflow challenges we observed, and as such, this viewpoint is the most foundational statement of the dbt project's goals.
- [The Original dbt-athena Maintainers](https://docs.getdbt.com/community/spotlight/original-dbt-athena-maintainers.md): The original dbt-athena Maintainers is a group of 5 people—Jérémy Guiselin, Mattia, Jesse Dobbelaere, Serhii Dimchenko, and Nicola...
- [Tips for organizing inclusive events](https://docs.getdbt.com/community/resources/organizing-inclusive-events.md): The dbt community is filled with dedicated community leaders who create opportunities for connection, learning and professional development within the analytics community.
- [Tyler Rouze](https://docs.getdbt.com/community/spotlight/tyler-rouze.md): My journey in data started all the way back in college where I studied Industrial Engineering. One of the core topics you learn in...
- [Writing contributions](https://docs.getdbt.com/community/contributing/contributing-writing.md): Contribute to the product documentation
- [Yasuhisa Yoshida](https://docs.getdbt.com/community/spotlight/yasuhisa-yoshida.md): I currently work as a data engineer at a startup called 10X. Specifically, I work with BigQuery to provide data marts for business...

## Docs

- [2022 dbt Cloud release notes](https://docs.getdbt.com/docs/dbt-versions/2022-release-notes.md): dbt Cloud release notes for 2022
- [2023 dbt Cloud release notes](https://docs.getdbt.com/docs/dbt-versions/2023-release-notes.md): dbt Cloud release notes for 2023
- [2024 dbt Cloud release notes](https://docs.getdbt.com/docs/dbt-versions/2024-release-notes.md): 2024 dbt Cloud release notes
- [About continuous integration (CI) in dbt](https://docs.getdbt.com/docs/deploy/about-ci.md): Use CI jobs in  to set up automation for testing code changes before merging to production. Additionally, enable Advanced CI features for these jobs to evaluate whether the code changes are producing the appropriate data changes you want by reviewing the comparison differences dbt provides.
- [About dbt Core versions](https://docs.getdbt.com/docs/dbt-versions/core.md): Learn about semantic versioning for dbt Core, and how long those versions are supported.
- [About dbt Insights EnterpriseEnterprise +](https://docs.getdbt.com/docs/explore/dbt-insights.md): Learn how to query data and perform exploratory data analysis using dbt Insights
- [About dbt integrations](https://docs.getdbt.com/docs/cloud-integrations/overview.md): Many data applications integrate with , enabling you to leverage the power of dbt for a variety of use cases and workflows.
- [About dbt LSP](https://docs.getdbt.com/docs/about-dbt-lsp.md): Learn about the dbt language server protocol features
- [About dbt Mesh](https://docs.getdbt.com/docs/mesh/about-mesh.md): Getting started with dbt Mesh patterns
- [About dbt Model Context Protocol (MCP)](https://docs.getdbt.com/docs/dbt-ai/about-mcp.md): Learn about the dbt MCP server
- [About dbt models](https://docs.getdbt.com/docs/build/models.md): Understand the role of dbt models transforming your data into analytics-ready datasets.
- [About dbt projects](https://docs.getdbt.com/docs/build/projects.md): A dbt project informs dbt about the context of your project and how to transform your data (build your data sets). By design, dbt enforces the top-level structure of a dbt project such as the dbt_project.yml file, the models directory, the snapshots directory, and so on. Within the directories of the top-level, you can organize your project in any way that meets the needs of your organization and data pipeline.
- [About documentation](https://docs.getdbt.com/docs/build/documentation.md): Learn how good documentation for your dbt models helps stakeholders discover and understand your datasets.
- [About Hybrid projects Enterprise +](https://docs.getdbt.com/docs/deploy/hybrid-projects.md): Learn how to upload dbt Core artifacts into the dbt platform to create and set up hybrid projects.
- [About Iceberg catalogs](https://docs.getdbt.com/docs/mesh/iceberg/about-catalogs.md): Understand how Iceberg catalogs fit into your dbt Mesh configurations.
- [About incremental models](https://docs.getdbt.com/docs/build/incremental-models-overview.md): This is an introduction on incremental models, when to use them, and how they work in dbt.
- [About incremental strategy](https://docs.getdbt.com/docs/build/incremental-strategy.md): Incremental strategies for materializations optimize performance by defining how to handle new and changed data.
- [About MetricFlow](https://docs.getdbt.com/docs/build/about-metricflow.md): Learn more about MetricFlow and its key concepts
- [About microbatch incremental models](https://docs.getdbt.com/docs/build/incremental-microbatch.md): Learn about the 'microbatch' strategy for incremental models.
- [About model governance](https://docs.getdbt.com/docs/mesh/govern/about-model-governance.md): Information about new features related to model governance
- [About state-aware orchestration Private previewEnterpriseEnterprise +](https://docs.getdbt.com/docs/deploy/state-aware-about.md): Learn about how state-aware orchestration automatically determines which models to build by detecting changes in code or data every time a job runs.
- [About the --empty flag](https://docs.getdbt.com/docs/build/empty-flag.md): Use the empty flag to test your code and build your tables without populating data.
- [About the --sample flag](https://docs.getdbt.com/docs/build/sample-flag.md): Use the sample flag to lower development time and reduce warehouse spend.
- [About the dbt Snowflake Native App Preview](https://docs.getdbt.com/docs/cloud-integrations/snowflake-native-app.md): An overview of the dbt Snowflake Native App for dbt accounts
- [About the dbt VS Code extension Preview](https://docs.getdbt.com/docs/about-dbt-extension.md): Bring all the speed and power of the dbt Fusion engine to your local development workflow.
- [Access Catalog from dbt platform features](https://docs.getdbt.com/docs/explore/access-from-dbt-cloud.md): Learn where and how to directly access and interact with Catalog from dbt platform features and products.
- [Access the dbt Insights interface EnterpriseEnterprise +](https://docs.getdbt.com/docs/explore/access-dbt-insights.md): Learn how to access the dbt Insights interface and run queries
- [Add data tests to your DAG](https://docs.getdbt.com/docs/build/data-tests.md): Configure dbt data tests to assess the quality of your input data and ensure accuracy in resulting datasets.
- [Add Exposures to your DAG](https://docs.getdbt.com/docs/build/exposures.md): Exposures make it possible to define and describe a downstream use of your dbt project, such as in a dashboard, application, or data science pipeline. By defining exposures, you can then:
- [Add groups to your DAG](https://docs.getdbt.com/docs/build/groups.md): When you define groups in dbt projects, you turn implicit relationships into an explicit grouping.
- [Add Seeds to your DAG](https://docs.getdbt.com/docs/build/seeds.md): Provide seed data files for your dbt models.
- [Add snapshots to your DAG](https://docs.getdbt.com/docs/build/snapshots.md): Configure snapshots in dbt to track changes to your data over time.
- [Add sources to your DAG](https://docs.getdbt.com/docs/build/sources.md): Define data source tables when developing in dbt.
- [Administer the Semantic Layer StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/use-dbt-semantic-layer/setup-sl.md): Seamlessly set up the credentials and tokens to start querying the dbt Semantic Layer.
- [Advanced CI EnterpriseEnterprise +](https://docs.getdbt.com/docs/deploy/advanced-ci.md): Advanced CI enables developers to compare changes by demonstrating the changes the code produces.
- [Advanced data modeling](https://docs.getdbt.com/docs/build/advanced-topics.md): Learn about advanced topics for dbt Semantic Layer and MetricFlow, such as modeling workflows and more.
- [Analyses](https://docs.getdbt.com/docs/build/analyses.md): Configure SQL files in dbt to create compiled code used for analyses.
- [Apache Iceberg Support](https://docs.getdbt.com/docs/mesh/iceberg/apache-iceberg-support.md): Understand dbt platform support for Iceberg catalogs.
- [Artifacts](https://docs.getdbt.com/docs/deploy/artifacts.md): Use artifacts to power your automated docs site and source freshness data.
- [Available integrations StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud-integrations/avail-sl-integrations.md): Discover the diverse range of partners that seamlessly integrate with the powerful dbt Semantic Layer, allowing you to query and unlock valuable insights from your data ecosystem.
- [BigQuery and Apache Iceberg](https://docs.getdbt.com/docs/mesh/iceberg/bigquery-iceberg-support.md): Understand BigQuery support for Apache Iceberg.
- [Build and view your docs with dbt](https://docs.getdbt.com/docs/explore/build-and-view-your-docs.md): Automatically generate project documentation as you run jobs.
- [Build your metrics](https://docs.getdbt.com/docs/build/build-metrics-intro.md): Learn about MetricFlow and build your metrics with semantic models
- [Cache common queries EnterpriseEnterprise +](https://docs.getdbt.com/docs/use-dbt-semantic-layer/sl-cache.md): Cache common queries to speed up performance and reduce query computation.
- [Changelog 2019 and 2020](https://docs.getdbt.com/docs/dbt-versions/release-notes/dbt-cloud-changelog-2019-2020.md): 2019 and 2020 Changelog for the dbt Cloud application
- [Changelog 2021](https://docs.getdbt.com/docs/dbt-versions/release-notes/dbt-cloud-changelog-2021.md): 2021 Changelog for the dbt Cloud application
- [Column-level lineage EnterpriseEnterprise +](https://docs.getdbt.com/docs/explore/column-level-lineage.md): Use dbt Catalog's column-level lineage to gain insights about your data at a granular level.
- [Community adapters](https://docs.getdbt.com/docs/community-adapters.md): Community adapters are adapter plugins contributed and maintained by members of the community. We welcome and encourage adapter plugins contributions from the dbt community.  Please be mindful that these community maintainers are intrepid volunteers who donate their time and effort — so be kind, understanding, and help out where you can!
- [Configure incremental models](https://docs.getdbt.com/docs/build/incremental-models.md): Learn how to configure and optimize incremental models when developing in dbt.
- [Configure your local setup](https://docs.getdbt.com/docs/configure-dbt-extension.md): Optimize your VS Code extension environment (files, env vars, connectivity).
- [Connect to adapters](https://docs.getdbt.com/docs/connect-adapters.md): Adapters are an essential component of dbt. At their most basic level, they are how dbt connects with the various supported data platforms. At a higher-level, adapters strive to give analytics engineers more transferrable skills as well as standardize how analytics projects are structured. Gone are the days where you have to learn a new language or flavor of SQL when you move to a new job that has a different data platform. That is the power of adapters in dbt &mdash; for more detail, refer to the Build, test, document, and promote adapters guide.
- [Consume metrics from your Semantic Layer StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/use-dbt-semantic-layer/consume-metrics.md): Learn how to query and consume metrics from your deployed dbt Semantic Layer using various tools and APIs.
- [Continuous deployment in dbt](https://docs.getdbt.com/docs/deploy/continuous-deployment.md): Learn about continuous deployment (CD) workflows 
- [Continuous integration in dbt](https://docs.getdbt.com/docs/deploy/continuous-integration.md): You can set up continuous integration (CI) checks to test every single change prior to deploying the code to production just like in a software development workflow.
- [Continuous integration jobs in dbt](https://docs.getdbt.com/docs/deploy/ci-jobs.md): Learn how to create and set up CI checks to test code changes before deploying to production.
- [Contribute to adapters](https://docs.getdbt.com/docs/contribute-core-adapters.md): The dbt Community exists to allow analytics practitioners share their knowledge, help others and collectively to drive forward the discipline of analytics engineering. There are opportunities here for everyone to contribute whether you're at the beginning of your analytics engineering journey or you are a seasoned data professional.
- [Conversion metrics](https://docs.getdbt.com/docs/build/conversion.md): Use Conversion metrics to measure conversion events.
- [Creating metrics](https://docs.getdbt.com/docs/build/metrics-overview.md): Metrics can be defined in the same or separate YAML files from semantic models within the same dbt project repo.
- [Cumulative metrics](https://docs.getdbt.com/docs/build/cumulative.md): Use Cumulative metrics to aggregate a measure over a given window.
- [Custom aliases](https://docs.getdbt.com/docs/build/custom-aliases.md): Configure custom aliases to override default naming conventions for models and other resources in dbt.
- [Custom databases](https://docs.getdbt.com/docs/build/custom-databases.md): Different warehouses have different names for logical databases. The information in this document covers "databases" on Snowflake, Redshift, and Postgres; "projects" on BigQuery; and "catalogs" on Databricks Unity Catalog.
- [Custom schemas](https://docs.getdbt.com/docs/build/custom-schemas.md): Configure custom schemas for your dbt model's tables and views in the database.
- [Custom target names](https://docs.getdbt.com/docs/build/custom-target-names.md): You can define a custom target name for any dbt job to correspond to settings in your dbt project.
- [Data health signals Preview](https://docs.getdbt.com/docs/explore/data-health-signals.md): Learn how data health signals offer a quick, at-a-glance view of data health when browsing your resources in dbt Catalog.
- [Data health tile EnterpriseEnterprise +](https://docs.getdbt.com/docs/explore/data-tile.md): Embed data health tiles in your dashboards to distill data health signals for data consumers.
- [Databricks and Apache Iceberg](https://docs.getdbt.com/docs/mesh/iceberg/databricks-iceberg-support.md): Understand Databricks support for Apache Iceberg.
- [dbt Catalog FAQs](https://docs.getdbt.com/docs/explore/dbt-explorer-faqs.md): Learn more with the FAQs about dbt Catalog, how it works, how to interact with it, and more.
- [dbt platform compatible track - changelog](https://docs.getdbt.com/docs/dbt-versions/compatible-track-changelog.md): The Compatible release track updates once per month, and it includes up-to-date open source versions as of the monthly release.
- [dbt Product lifecycles](https://docs.getdbt.com/docs/dbt-versions/product-lifecycles.md): Learn about dbt Labs' product lifecycles.
- [dbt release notes](https://docs.getdbt.com/docs/dbt-versions/dbt-cloud-release-notes.md): dbt release notes
- [dbt Semantic Layer architecture](https://docs.getdbt.com/docs/use-dbt-semantic-layer/sl-architecture.md): dbt Semantic Layer product architecture and related questions.
- [dbt Semantic Layer FAQs](https://docs.getdbt.com/docs/use-dbt-semantic-layer/sl-faqs.md): Read the FAQs to learn more about the dbt Semantic Layer, how it works, how to build metrics, integrations, and more.
- [dbt Semantic Layer StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/use-dbt-semantic-layer/dbt-sl.md): Learn how the dbt Semantic Layer enables data teams to centrally define and query metrics.
- [dbt support](https://docs.getdbt.com/docs/dbt-support.md): Support for dbt is available to all users through the following channels:
- [dbt tips and tricks](https://docs.getdbt.com/docs/build/dbt-tips.md): Check out any dbt-related tips and tricks to help you work faster and be more productive.
- [dbt VS Code extension features Preview](https://docs.getdbt.com/docs/dbt-extension-features.md): The dbt VS Code extension is backed by the dbt Fusion engine and a powerful LSP.
- [Deploy dbt](https://docs.getdbt.com/docs/deploy/deployments.md): Use 's capabilities to seamlessly run a dbt job in production or staging environments. Rather than run dbt commands manually from the command line, you can leverage the 's in-app scheduling to automate how and when you execute dbt.
- [Deploy jobs](https://docs.getdbt.com/docs/deploy/deploy-jobs.md): Learn how to create and schedule deploy jobs in dbt for the scheduler to run. When you run with dbt, you get built-in observability, logging, and alerting.
- [Deploy your metrics StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/use-dbt-semantic-layer/deploy-sl.md): Deploy the dbt Semantic Layer in dbt by running a job to materialize your metrics.
- [Deployment environments](https://docs.getdbt.com/docs/deploy/deploy-environments.md): Learn about dbt's deployment environment to seamlessly schedule jobs or enable CI.
- [Derived metrics](https://docs.getdbt.com/docs/build/derived.md): Derived metrics is defined as an expression of other metrics..
- [Dimensions](https://docs.getdbt.com/docs/build/dimensions.md): Dimensions determine the level of aggregation for a metric, and are non-aggregatable expressions.
- [Discover data with Catalog](https://docs.getdbt.com/docs/explore/explore-projects.md): Learn about Catalog and how to interact with it to understand, improve, and leverage your dbt projects.
- [Enhance your code](https://docs.getdbt.com/docs/build/enhance-your-code.md): Learn how you can enhance your code
- [Enhance your models](https://docs.getdbt.com/docs/build/enhance-your-models.md): Learn how you can enhance your models
- [Entities](https://docs.getdbt.com/docs/build/entities.md): Entities are real-world concepts that correspond to key parts of your business, such as customers, transactions, and ad campaigns.
- [Environment variables](https://docs.getdbt.com/docs/build/environment-variables.md): Use environment variables to customize the behavior of your dbt project.
- [Explore multiple projects](https://docs.getdbt.com/docs/explore/explore-multiple-projects.md): Learn about project-level lineage in dbt Catalog and its uses.
- [Explore your data](https://docs.getdbt.com/docs/explore/explore-your-data.md): Explore your data, models, and other resources in dbt
- [External metadata ingestion EnterpriseEnterprise + Preview](https://docs.getdbt.com/docs/explore/external-metadata-ingestion.md): Connect directly to your data warehouse, giving you visibility into tables, views, and other resources that aren't defined in dbt with dbt Catalog.
- [Fill null values for metrics](https://docs.getdbt.com/docs/build/fill-nulls-advanced.md): Learn about advanced topics for dbt Semantic Layer and MetricFlow, such as modeling workflows and more.
- [Frequently asked questions](https://docs.getdbt.com/docs/faqs.md): Our Frequently Asked Questions (FAQs) section is a space where you can find an answer to some questions we get asked a lot (but that we’re happy to answer!). If you have a question or are still stuck on something, just reach out to us by emailing support@getdbt.com or clicking on the chat widget, and we’ll do our best to help out.
- [Global navigation StarterEnterpriseEnterprise + Preview](https://docs.getdbt.com/docs/explore/global-navigation.md): Learn how to enable and use global navigation to search, explore, and analyze data assets across all your dbt projects and connected metadata sources.
- [Google Sheets StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud-integrations/semantic-layer/gsheets.md): Integrate with Google Sheets to query your metrics in a spreadsheet.
- [Hooks and operations](https://docs.getdbt.com/docs/build/hooks-operations.md): Customize dbt workflows using hooks and operations.
- [Hybrid setup Enterprise +](https://docs.getdbt.com/docs/deploy/hybrid-setup.md): Learn how to set up hybrid projects in the dbt platform.
- [Install the dbt VS Code extension Preview](https://docs.getdbt.com/docs/install-dbt-extension.md): Installation instructions for the dbt extension.
- [Integrate Claude with dbt MCP](https://docs.getdbt.com/docs/dbt-ai/integrate-mcp-claude.md): Guide to set up claude with dbt-mcp
- [Integrate Cursor with dbt MCP](https://docs.getdbt.com/docs/dbt-ai/integrate-mcp-cursor.md): Guide to set up Cursor with dbt-mcp
- [Integrate VS Code with MCP](https://docs.getdbt.com/docs/dbt-ai/integrate-mcp-vscode.md): Guide to set up VS Code with dbt-mcp
- [Integrate with other orchestration tools](https://docs.getdbt.com/docs/deploy/deployment-tools.md): Alongside , discover other ways to schedule and run your dbt jobs with the help of tools such as the ones described on this page.
- [Jinja and macros](https://docs.getdbt.com/docs/build/jinja-macros.md): Enhance your SQL with Jinja and macros when developing in dbt to create reusable, modular logic.
- [Job commands](https://docs.getdbt.com/docs/deploy/job-commands.md): How to use dbt commands to set tasks for your dbt jobs.
- [Job notifications](https://docs.getdbt.com/docs/deploy/job-notifications.md): Set up notifications in dbt to receive email or Slack alerts about job run status.
- [Job scheduler](https://docs.getdbt.com/docs/deploy/job-scheduler.md): The dbt job scheduler queues scheduled or API-triggered runs, before preparing the job to enter cloud data platform. Build observability into transformation workflows with the in-app scheduling, logging, and alerting.
- [Jobs in the dbt platform](https://docs.getdbt.com/docs/deploy/jobs.md): Learn about the different job types in dbt and what their differences are.
- [Joins](https://docs.getdbt.com/docs/build/join-logic.md): Joins allow you to combine data from different tables and create new metrics
- [Materializations](https://docs.getdbt.com/docs/build/materializations.md): Configure materializations in dbt to control how the SQL is run and resulting data is stored.
- [Measures](https://docs.getdbt.com/docs/build/measures.md): Measures are aggregations performed on columns in your model.
- [Merge jobs in dbt StarterEnterprise](https://docs.getdbt.com/docs/deploy/merge-jobs.md): Learn how to trigger a dbt job run when a Git pull request merges.
- [MetricFlow commands](https://docs.getdbt.com/docs/build/metricflow-commands.md): Query metrics and metadata in your dbt project with the MetricFlow commands.
- [MetricFlow time spine](https://docs.getdbt.com/docs/build/metricflow-time-spine.md): MetricFlow expects a default time spine table called metricflow_time_spine
- [Metrics as dimensions with metric filters](https://docs.getdbt.com/docs/build/ref-metrics-in-filters.md): Add metrics as dimensions to your metric filters to create more complex metrics and gain more insights.
- [Microsoft Excel StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud-integrations/semantic-layer/excel.md): Integrate with Excel to query your metrics in a spreadsheet.
- [Model access](https://docs.getdbt.com/docs/mesh/govern/model-access.md): Define model access with group capabilities
- [Model contracts](https://docs.getdbt.com/docs/mesh/govern/model-contracts.md): Model contracts define a set of parameters validated during transformation
- [Model notifications](https://docs.getdbt.com/docs/deploy/model-notifications.md): While a job is running, receive email notifications in real time about any issues with your models and tests. 
- [Model performance EnterpriseEnterprise +](https://docs.getdbt.com/docs/explore/model-performance.md): Learn about the performance of your models so you can make improvements to save time and money.
- [Model query history EnterpriseEnterprise +](https://docs.getdbt.com/docs/explore/model-query-history.md): Import and auto-generate exposures from dashboards and understand how models are used in downstream tools for a richer lineage.
- [Model versions](https://docs.getdbt.com/docs/mesh/govern/model-versions.md): Version models to help with lifecycle management
- [Monitor jobs and alerts](https://docs.getdbt.com/docs/deploy/monitor-jobs.md): Monitor your dbt job and set up alerts to ensure seamless orchestration and optimize your data transformations
- [Navigate the dbt Insights interface EnterpriseEnterprise +](https://docs.getdbt.com/docs/explore/navigate-dbt-insights.md): Learn how to navigate the dbt Insights interface
- [Navigating the state-aware interface](https://docs.getdbt.com/docs/deploy/state-aware-interface.md): Learn how to navigate the state-aware orchestration interface for better visibility into model builds and cost tracking.
- [Orchestrate downstream exposures EnterpriseEnterprise +Beta](https://docs.getdbt.com/docs/cloud-integrations/orchestrate-exposures.md): Use dbt to proactively refresh the underlying data sources (like Tableau extracts) during scheduled dbt jobs.
- [Organize your outputs](https://docs.getdbt.com/docs/build/organize-your-outputs.md): Learn how you can organize your outputs
- [Packages](https://docs.getdbt.com/docs/build/packages.md): dbt packages help modularize code and transform data efficiently.
- [Parallel microbatch execution](https://docs.getdbt.com/docs/build/parallel-batch-execution.md): Learn about the 'parallel batch execution' strategy for incremental models.
- [Power BI StarterEnterpriseEnterprise +Preview](https://docs.getdbt.com/docs/cloud-integrations/semantic-layer/power-bi.md): Use Power BI to query the dbt Semantic Layer and produce dashboards with trusted data.
- [Preview new and experimental features in the dbt platform](https://docs.getdbt.com/docs/dbt-versions/experimental-features.md): Gain early access to many new dbt Labs experimental features by enabling this in your profile.
- [Project dependencies EnterpriseEnterprise +](https://docs.getdbt.com/docs/mesh/govern/project-dependencies.md): Reference public models across dbt projects
- [Project recommendations EnterpriseEnterprise +](https://docs.getdbt.com/docs/explore/project-recommendations.md): dbt Catalog provides recommendations that you can take to improve the quality of your dbt project.
- [Project variables](https://docs.getdbt.com/docs/build/project-variables.md): Use dbt project variables to configure conditional or reusable logic across models and other resources.
- [Python models](https://docs.getdbt.com/docs/build/python-models.md): Configure Python models to enhance your dbt project.
- [Ratio metrics](https://docs.getdbt.com/docs/build/ratio.md): Use ratio metrics to create a ratio out of two measures. 
- [Release tracks in dbt platform](https://docs.getdbt.com/docs/dbt-versions/cloud-release-tracks.md): Learn how to get automatic upgrades to dbt in the dbt platform. Access new features and enhancements as soon as they become available.
- [Retry your dbt jobs](https://docs.getdbt.com/docs/deploy/retry-jobs.md): Rerun your errored jobs from start or the failure point.
- [Run visibility](https://docs.getdbt.com/docs/deploy/run-visibility.md): Monitor your jobs to make performance improvements.
- [Saved queries](https://docs.getdbt.com/docs/build/saved-queries.md): Saved queries are a way to save commonly used queries in MetricFlow. They can be used to save time and avoid writing the same query over and over again.
- [Semantic models](https://docs.getdbt.com/docs/build/semantic-models.md): Semantic models are YAML abstractions on top of a dbt mode, connected via joining keys as edges
- [Set up automatic exposures in Tableau EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud-integrations/downstream-exposures-tableau.md): Set up and visualize exposures automatically by auto-generating them from Tableau dashboards, helping you understand how models are used in downstream tools for a richer lineage.
- [Set up local MCP](https://docs.getdbt.com/docs/dbt-ai/setup-local-mcp.md): Learn how to set up the local dbt-mcp server
- [Set up remote MCP](https://docs.getdbt.com/docs/dbt-ai/setup-remote-mcp.md): Learn how to set up the remote dbt-mcp server
- [Set up the dbt Snowflake Native App Preview](https://docs.getdbt.com/docs/cloud-integrations/set-up-snowflake-native-app.md): Learn how to set up the dbt Snowflake Native App
- [Setting up state-aware orchestration Private previewEnterpriseEnterprise +](https://docs.getdbt.com/docs/deploy/state-aware-setup.md): Set up state-aware orchestration to automatically determine which models to build by detecting changes in code or data every time a job runs.
- [Simple metrics](https://docs.getdbt.com/docs/build/simple.md): Use simple metrics to directly reference a single measure.
- [Snowflake and Apache Iceberg](https://docs.getdbt.com/docs/mesh/iceberg/snowflake-iceberg-support.md): Understand Snowflake support for Apache Iceberg.
- [Source freshness](https://docs.getdbt.com/docs/deploy/source-freshness.md): Validate that data freshness meets expectations and alert if stale.
- [SQL models](https://docs.getdbt.com/docs/build/sql-models.md): SQL models are the building blocks of your dbt project.
- [Supported data platforms](https://docs.getdbt.com/docs/supported-data-platforms.md): Connect dbt to any data platform in dbt, using a dedicated adapter plugin
- [Tableau StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud-integrations/semantic-layer/tableau.md): Use Tableau worksheets to query the dbt Semantic Layer and produce dashboards with trusted date.
- [Trusted adapters](https://docs.getdbt.com/docs/trusted-adapters.md): Trusted adapters take part in the Trusted Adapter Program, including a commitment to meet the program's requirements. They are maintained by dbt Labs, partners, and community members. Trusted adapters in  undergo an additional rigorous process that covers development, documentation, user experience, and maintenance requirements. We strongly recommend using them in production environments. For further details, refer to What it means to be trusted.
- [Unit tests](https://docs.getdbt.com/docs/build/unit-tests.md): Implement unit tests to validate your dbt code.
- [Upgrade versions in dbt platform](https://docs.getdbt.com/docs/dbt-versions/upgrade-dbt-version-in-cloud.md): In , both jobs and environments are configured to use a specific version of . The version can be upgraded at any time.
- [Upgrading to dbt utils v1.0](https://docs.getdbt.com/docs/dbt-versions/core-upgrade/Older versions/upgrading-to-dbt-utils-v1.0.md): New features and breaking changes to consider as you upgrade to dbt utils v1.0.
- [Upgrading to the dbt Fusion engine (v2.0)](https://docs.getdbt.com/docs/dbt-versions/core-upgrade/upgrading-to-fusion.md): New features and changes in Fusion
- [Upgrading to v1.0](https://docs.getdbt.com/docs/dbt-versions/core-upgrade/Older versions/upgrading-to-v1.0.md): New features and changes in dbt Core v1.0
- [Upgrading to v1.1](https://docs.getdbt.com/docs/dbt-versions/core-upgrade/Older versions/upgrading-to-v1.1.md): New features and changes in dbt Core v1.1
- [Upgrading to v1.1 Beta](https://docs.getdbt.com/docs/dbt-versions/core-upgrade/upgrading-to-v1.11.md): New features and changes in dbt Core v1.11
- [Upgrading to v1.10](https://docs.getdbt.com/docs/dbt-versions/core-upgrade/upgrading-to-v1.10.md): New features and changes in dbt Core v1.10
- [Upgrading to v1.2](https://docs.getdbt.com/docs/dbt-versions/core-upgrade/Older versions/upgrading-to-v1.2.md): New features and changes in dbt Core v1.2
- [Upgrading to v1.3](https://docs.getdbt.com/docs/dbt-versions/core-upgrade/Older versions/upgrading-to-v1.3.md): New features and changes in dbt Core v1.3
- [Upgrading to v1.4](https://docs.getdbt.com/docs/dbt-versions/core-upgrade/Older versions/upgrading-to-v1.4.md): New features and changes in dbt Core v1.4
- [Upgrading to v1.5](https://docs.getdbt.com/docs/dbt-versions/core-upgrade/Older versions/upgrading-to-v1.5.md): New features and changes in dbt Core v1.5
- [Upgrading to v1.6](https://docs.getdbt.com/docs/dbt-versions/core-upgrade/Older versions/upgrading-to-v1.6.md): New features and changes in dbt Core v1.6
- [Upgrading to v1.7](https://docs.getdbt.com/docs/dbt-versions/core-upgrade/upgrading-to-v1.7.md): New features and changes in dbt Core v1.7
- [Upgrading to v1.8](https://docs.getdbt.com/docs/dbt-versions/core-upgrade/upgrading-to-v1.8.md): New features and changes in dbt Core v1.8
- [Upgrading to v1.9](https://docs.getdbt.com/docs/dbt-versions/core-upgrade/upgrading-to-v1.9.md): New features and changes in dbt Core v1.9
- [User-defined functions Beta](https://docs.getdbt.com/docs/build/udfs.md): Learn how to add user-defined functions (UDFs) to your dbt projects.
- [Validations](https://docs.getdbt.com/docs/build/validation.md): The Semantic Layer, powered by MetricFlow, has three types of built-in validations, including Parsing Validation, Semantic Validation, and Data Warehouse validation, which are performed in a sequential and blocking manner.
- [Version upgrade guides](https://docs.getdbt.com/docs/dbt-versions/core-upgrade.md): Learn what's new in the latest version of dbt Core.
- [View documentation](https://docs.getdbt.com/docs/build/view-documentation.md): Learn how robust documentation for your dbt models helps stakeholders discover and understand your datasets.
- [Visualize and orchestrate downstream exposures EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud-integrations/downstream-exposures.md): Learn how to use dbt to automatically generate exposures from dashboards and proactively refresh the underlying data sources during scheduled dbt jobs.
- [Visualize and orchestrate downstream exposures EnterpriseEnterprise +](https://docs.getdbt.com/docs/deploy/orchestrate-exposures.md): Learn how to use dbt to automatically generate downstream exposures from dashboards and proactively refresh the underlying data sources during scheduled dbt jobs.
- [Visualize downstream exposures EnterpriseEnterprise +](https://docs.getdbt.com/docs/explore/view-downstream-exposures.md): Configure downstream exposures automatically from dashboards and understand how models are used in downstream tools for a richer downstream lineage.
- [Webhooks for your jobs StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/deploy/webhooks.md): Get real-time notifications about your dbt jobs with webhooks.
- [Weekly dbt single-tenant release notes](https://docs.getdbt.com/docs/dbt-versions/dbt-cloud-release-notes-gen.md): Release notes for weekly single-tenant updates.
- [Write queries with exports StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/use-dbt-semantic-layer/exports.md): Use exports to write tables to the data platform on a schedule.

## Faqs

- [[Error] Could not find my_project package](https://docs.getdbt.com/faqs/Troubleshooting/dispatch-could-not-find-package.md): Macros missing from packages
- [Account-specific features](https://docs.getdbt.com/faqs/Accounts/account-specific-features.md): Account-specific features
- [Add a seed file](https://docs.getdbt.com/faqs/Project/add-a-seed.md): Learn how to add a seed file to your project
- [Are the results of freshness stored anywhere?](https://docs.getdbt.com/faqs/Project/dbt-source-freshness.md): How to access Source Freshness results
- [Are there any example dbt projects?](https://docs.getdbt.com/faqs/Project/example-projects.md): List of example dbt projects
- [Can I add tests and descriptions in a config block?](https://docs.getdbt.com/faqs/Project/properties-not-in-config.md): Types of properties defined in config blocks
- [Can I build my models in a schema other than my target schema or split my models across multiple schemas?](https://docs.getdbt.com/faqs/Models/model-custom-schemas.md): You can build models outside target schema
- [Can I build my seeds in a schema other than my target schema or can I split my seeds across multiple schemas?](https://docs.getdbt.com/faqs/Seeds/seed-custom-schemas.md): Use schema config in your dbt_project.yml file
- [Can I connect my dbt project to two databases?](https://docs.getdbt.com/faqs/Warehouse/connecting-to-two-dbs-not-allowed.md): Prepare your warehouse for dbt transformations
- [Can I define private packages in the dependencies.yml file?](https://docs.getdbt.com/faqs/Project_ref/define-private-packages.md): Learn how to define private packages in your project
- [Can I document things other than models, like sources, seeds, and snapshots?](https://docs.getdbt.com/faqs/Docs/document-other-resources.md): Using the description key to document resources
- [Can I pay via invoice?](https://docs.getdbt.com/faqs/Accounts/payment-accepted.md): What payments types are accepted
- [Can I set a different connection at the environment level?](https://docs.getdbt.com/faqs/Environments/diff-database-environment.md): Separate projects for different environments workaround
- [Can I set test failure thresholds?](https://docs.getdbt.com/faqs/Tests/custom-test-thresholds.md): Use configs to set custom failure thresholds in tests
- [Can I store my data tests in a directory other than the `tests` directory in my project?](https://docs.getdbt.com/faqs/Tests/configurable-data-test-path.md): Where to store data tests in a directory
- [Can I store my models in a directory other than the `models` directory in my project?](https://docs.getdbt.com/faqs/Models/configurable-model-path.md): How to name models directory
- [Can I store my seeds in a directory other than the `seeds` directory in my project?](https://docs.getdbt.com/faqs/Seeds/configurable-data-path.md): Where to store seeds in a directory
- [Can I store my snapshots in a directory other than the `snapshot` directory in my project?](https://docs.getdbt.com/faqs/Accounts/configurable-snapshot-path.md): You can see how to change snapshots directory in your project
- [Can I test the uniqueness of two columns?](https://docs.getdbt.com/faqs/Tests/uniqueness-two-columns.md): Options to test uniqueness of two columns
- [Can I use a YAML file extension?](https://docs.getdbt.com/faqs/Project/yaml-file-extension.md): dbt will only search for files with a `.yml` file extension
- [Can I use environment variables in my profile?](https://docs.getdbt.com/faqs/Environments/profile-env-vars.md): Use env_var in your profile
- [Can I use seeds to load raw data?](https://docs.getdbt.com/faqs/Seeds/load-raw-data-with-seed.md): Use seeds to load business specific logic
- [Can self-hosted GitLab instances only be connected via dbt Enterprise plans?](https://docs.getdbt.com/faqs/Git/gitlab-selfhosted.md): Self hosted GitLab instances plan availability
- [Debug Snapshot target is not a snapshot table errors](https://docs.getdbt.com/faqs/Snapshots/snapshot-target-is-not-a-snapshot-table.md): Debugging Snapshot target is not a snapshot table
- [Do hooks run with seeds?](https://docs.getdbt.com/faqs/Seeds/seed-hooks.md): Run hooks with seeds and configure them in project.yml file
- [Do hooks run with snapshots?](https://docs.getdbt.com/faqs/Snapshots/snapshot-hooks.md): Run hooks with snapshots
- [Do I need to add a YAML entry for column for it to appear in the docs site?](https://docs.getdbt.com/faqs/Docs/document-all-columns.md): All columns appear in your docs site
- [Do I need to create my target schema before running dbt?](https://docs.getdbt.com/faqs/Models/create-a-schema.md): Target schema is checked or created for you before running dbt
- [Do ref-able resource names need to be unique?](https://docs.getdbt.com/faqs/Project/unique-resource-names.md): Unique resource names to build dependencies
- [Does dbt offer extract and load functionality?](https://docs.getdbt.com/faqs/Project/transformation-tool.md): dbt is a transformation tool
- [Does my `.yml` file containing tests and descriptions need to be named `schema.yml`?](https://docs.getdbt.com/faqs/Project/schema-yml-name.md): Naming your Tests and Descriptions files
- [Does my operating system have prerequisites?](https://docs.getdbt.com/faqs/Core/install-pip-os-prereqs.md.md): You can check whether your operating system has prerequisites for installing dbt Core.
- [Errors importing a repository on dbt project set up](https://docs.getdbt.com/faqs/Troubleshooting/error-importing-repo.md): Errors importing a repository on dbt project set up
- [GitLab token refresh message](https://docs.getdbt.com/faqs/Git/gitlab-token-refresh.md): Learn how to resolve GitLab token refresh messages during your CI jobs
- [How can I connect dbt to a Google Source repository?](https://docs.getdbt.com/faqs/Git/google-cloud-repo.md): Use SSH URL method to connect to Google Source Repo
- [How can I consolidate projects in dbt?](https://docs.getdbt.com/faqs/Project/consolidate-projects.md): Consolidating projects in dbt
- [How can I fix my .gitignore file?](https://docs.getdbt.com/faqs/Git/gitignore.md): Use these instructions to fix your gitignore file
- [How can I fix my .gitignore file?](https://docs.getdbt.com/faqs/Troubleshooting/gitignore.md): Use these instructions to fix your gitignore file
- [How can I see the SQL that dbt is running?](https://docs.getdbt.com/faqs/Runs/checking-logs.md): Review logs to check the SQL dbt is running
- [How can I set up the right permissions in BigQuery?](https://docs.getdbt.com/faqs/Warehouse/bq-impersonate-service-account-setup.md): Use service account to set up permissions in BigQuery
- [How can I update my billing information?](https://docs.getdbt.com/faqs/Accounts/change-billing.md): Instructions on how to update your billing info
- [How can we move our project from a managed repository, to a self-hosted repository?](https://docs.getdbt.com/faqs/Git/managed-repo.md): Email Support to request your managed repository
- [How did dbt choose which schema to build my models in?](https://docs.getdbt.com/faqs/Project/which-schema.md): You can change your target schema in your Environment Settings.
- [How do I access documentation in dbt Catalog?](https://docs.getdbt.com/faqs/Docs/sharing-documentation.md): Use read-only seats to share documentation
- [How do I build one seed at a time?](https://docs.getdbt.com/faqs/Seeds/build-one-seed.md): Use select flag to build one seed at a time
- [How do I change a user license type to read-only in dbt?](https://docs.getdbt.com/faqs/Accounts/change-user-license.md): Changing a user license type to read-only in dbt
- [How do I create dependencies between models?](https://docs.getdbt.com/faqs/Models/create-dependencies.md): Using ref function to create dependencies
- [How do I debug my Jinja?](https://docs.getdbt.com/faqs/Project/debugging-jinja.md): Using target folder or log function to debug Jinja
- [How do I define a column type?](https://docs.getdbt.com/faqs/Project/define-a-column-type.md): Using cast function to define a column type
- [How do I delete a project in dbt?](https://docs.getdbt.com/faqs/Project/delete-a-project.md): Deleting a project in dbt
- [How do I delete a user in dbt?](https://docs.getdbt.com/faqs/Accounts/delete-users.md): Deleting a user in dbt
- [How do I document macros?](https://docs.getdbt.com/faqs/Docs/documenting-macros.md): You can use a schema file to document macros
- [How do I exclude a table from a freshness snapshot?](https://docs.getdbt.com/faqs/Project/exclude-table-from-freshness.md): Use null to exclude a table from a freshness snapshot
- [How do I load data into my warehouse?](https://docs.getdbt.com/faqs/Warehouse/loading-data.md): Recommendations on tools to load data to warehouse
- [How do I populate the owner column in the generated docs?](https://docs.getdbt.com/faqs/Docs/modify-owner-column.md): Modify owner column
- [How do I preserve leading zeros in a seed?](https://docs.getdbt.com/faqs/Seeds/leading-zeros-in-seed.md): Use column types to include leading zeros in seed
- [How do I remove deleted models from my data warehouse?](https://docs.getdbt.com/faqs/Models/removing-deleted-models.md): Remove deleted models directly in your data warehouse
- [How do I run data tests on just my sources?](https://docs.getdbt.com/faqs/Tests/testing-sources.md): Use the select source command to test sources
- [How do I run models downstream of a seed?](https://docs.getdbt.com/faqs/Runs/run-downstream-of-seed.md): You run models downstread using model selection syntax
- [How do I run models downstream of one source?](https://docs.getdbt.com/faqs/Runs/running-model-downstream-of-source.md): Use source selector to run models downstream of a source
- [How do I run one model at a time?](https://docs.getdbt.com/faqs/Runs/run-one-model.md): Use select flags to run one model at a time
- [How do I run one snapshot at a time?](https://docs.getdbt.com/faqs/Runs/run-one-snapshot.md): Use select flags to run one snapshot at a time
- [How do I set a datatype for a column in my seed?](https://docs.getdbt.com/faqs/Seeds/seed-datatypes.md): Use column_types to set a datatype
- [How do I snapshot freshness for one source only?](https://docs.getdbt.com/faqs/Snapshots/snapshotting-freshness-for-one-source.md): Use select flag to snapshot for specific sources
- [How do I specify column types?](https://docs.getdbt.com/faqs/Models/specifying-column-types.md): Specify column types in models
- [How do I test and document seeds?](https://docs.getdbt.com/faqs/Tests/testing-seeds.md): Use a schema file to test and document seeds
- [How do I test one model at a time?](https://docs.getdbt.com/faqs/Tests/test-one-model.md): Use select flag to test one model at a time
- [How do I transfer account ownership to another user?](https://docs.getdbt.com/faqs/Accounts/transfer-account.md): Instructions on how to transfer your dbt user account to another user
- [How do I use the 'Custom Branch' settings in a dbt Environment?](https://docs.getdbt.com/faqs/Environments/custom-branch-settings.md): Use custom code from your repository
- [How do I write long-form explanations in my descriptions?](https://docs.getdbt.com/faqs/Docs/long-descriptions.md): Write long descriptions in your documentation
- [How often should I run the snapshot command?](https://docs.getdbt.com/faqs/Runs/snapshot-frequency.md): Snapshot command intended to run on hourly/daily schedule 
- [How should I structure my project?](https://docs.getdbt.com/faqs/Project/structure-a-project.md): Recommendations on how to structure project
- [How to delete a job or environment in dbt?](https://docs.getdbt.com/faqs/Environments/delete-environment-job.md): How to delete a job or environment
- [How to generate HAR files](https://docs.getdbt.com/faqs/Troubleshooting/generate-har-file.md): How to generate HAR files for debugging
- [How to migrate git providers](https://docs.getdbt.com/faqs/Git/git-migration.md): Learn how to migrate git providers in dbt with minimal disruption.
- [How to upgrade a dbt account](https://docs.getdbt.com/faqs/Accounts/cloud-upgrade-instructions.md): Instructions for upgrading a dbt account after the trial ends.
- [I got an "unused model configurations" error message, what does this mean?](https://docs.getdbt.com/faqs/Troubleshooting/unused-model-configurations.md): Model configurations error message
- [I need to use quotes to select from my source, what should I do?](https://docs.getdbt.com/faqs/Models/source-quotes.md): Use quoting property to quote values
- [I'm getting a "Partial parsing enabled: 1 files deleted, 0 files added, 2 files changed" compilation error in dbt?](https://docs.getdbt.com/faqs/Troubleshooting/partial-parsing-error.md): Delete partial_parse file
- [I'm getting a "Session occupied" error in dbt CLI?](https://docs.getdbt.com/faqs/Troubleshooting/long-sessions-cloud-cli.md): How to debug long-running sessions in dbt CLI
- [I'm receiving a 'This run exceeded your account's run memory limits' error in my failed job](https://docs.getdbt.com/faqs/Troubleshooting/job-memory-limits.md): Use incremental models or optimize queries for job failures due to exceeded memory limits.
- [I'm receiving a "Permission denied while getting Drive credential" error when trying to query from Google Drive?](https://docs.getdbt.com/faqs/Troubleshooting/access-gdrive-credential.md): Grant BigQuery service account access
- [I'm receiving a 403 error 'Forbidden: Access denied' when using service tokens](https://docs.getdbt.com/faqs/Troubleshooting/ip-restrictions.md): All service token traffic is now subject to IP restrictions. To resolve 403 errors, add your third-party integration CIDRs (network addresses) to the allowlist.
- [I'm receiving a git rev-list master error in the IDE?](https://docs.getdbt.com/faqs/Troubleshooting/git-revlist-error.md): Primary branch not recognized
- [I'm receiving a NoneType object has no attribute error in the IDE?](https://docs.getdbt.com/faqs/Troubleshooting/nonetype-ide-error.md): Copy SSH key to your warehouse
- [I'm receiving a Runtime Error Could not find profile named 'user' error?](https://docs.getdbt.com/faqs/Troubleshooting/runtime-error-could-not-find-profile.md): Re-authorize your credentials on Profile Settings
- [I'm receiving an 'Your IDE session experienced an unknown error and was terminated. Please contact support'.](https://docs.getdbt.com/faqs/Troubleshooting/ide-session-unknown-error.md): Add a repository when seeing IDE unknown error
- [I'm receiving an `Failed ALPN` error when trying to connect to the dbt Semantic Layer.](https://docs.getdbt.com/faqs/Troubleshooting/sl-alpn-error.md): To resolve the 'Failed ALPN' error in the dbt Semantic Layer, create a SSL interception exception for the dbt domain.
- [I'm seeing a 'GitHub and dbt latest permissions' error](https://docs.getdbt.com/faqs/Git/github-permissions.md): GitHub and dbt permissions error
- [I'm seeing a Gitlab authentication out of date error loop](https://docs.getdbt.com/faqs/Git/gitlab-authentication.md): GitLab and dbt deploy key mismatch 
- [I'm seeing a Gitlab authentication out of date error loop](https://docs.getdbt.com/faqs/Troubleshooting/gitlab-authentication.md): GitLab and dbt deploy key mismatch 
- [If I can name these files whatever I'd like, what should I name them?](https://docs.getdbt.com/faqs/Project/resource-yml-name.md): Recommendations on how to name your files
- [If I rerun dbt, will there be any downtime as models are rebuilt?](https://docs.getdbt.com/faqs/Models/run-downtime.md): No downtime when re-building models in dbt 
- [If models can only be `select` statements, how do I insert records?](https://docs.getdbt.com/faqs/Models/insert-records.md): Incremental models to insert records
- [My compiled SQL has a lot of spaces and new lines, how can I get rid of it?](https://docs.getdbt.com/faqs/Jinja/jinja-whitespace.md): Managing whitespace control
- [One of my tests failed, how can I debug it?](https://docs.getdbt.com/faqs/Runs/failed-tests.md): You can debug failed tests by finding the SQL
- [Receiving a 'Could not parse dbt_project.yml' error in dbt job](https://docs.getdbt.com/faqs/Troubleshooting/could-not-parse-project.md): Receiving a 'Could not parse dbt_project.yml' error in dbt? This error is typically caused by a tab indentation in your dbt_project.yml file.
- [Receiving a `Failed to connect to DB` error when connecting to Snowflake](https://docs.getdbt.com/faqs/Troubleshooting/failed-snowflake-oauth-connection.md): Edit your OAuth Security integration when you see error
- [Receiving an `authentication has expired` error when trying to run queries in the IDE.](https://docs.getdbt.com/faqs/Troubleshooting/auth-expired-error.md): Reauthenticate warehouse when seeing `authentication has expired` error
- [Should I use separate files to declare resource properties, or one large file?](https://docs.getdbt.com/faqs/Project/multiple-resource-yml-files.md): Structuring your files and project
- [The columns of my seed changed, and now I get an error when running the `seed` command, what should I do?](https://docs.getdbt.com/faqs/Seeds/full-refresh-seed.md): Rerun the command with a `--full-refresh` flag
- [Unable to trigger a CI job with GitLab](https://docs.getdbt.com/faqs/Troubleshooting/gitlab-webhook.md): Unable to trigger a CI job
- [What are the best practices for installing dbt Core with pip?](https://docs.getdbt.com/faqs/Core/install-pip-best-practices.md.md): Instructions on how to install dbt Core with pip
- [What data tests are available for me to use in dbt?](https://docs.getdbt.com/faqs/Tests/available-tests.md): Types of data tests to use in dbt
- [What data tests should I add to my project?](https://docs.getdbt.com/faqs/Tests/recommended-tests.md): Recommended data tests for project
- [What happens if I add new columns to my snapshot query?](https://docs.getdbt.com/faqs/Snapshots/snapshot-schema-changes.md): Reconcile changes when adding new columns in snapshot query
- [What happens if one of my runs fails?](https://docs.getdbt.com/faqs/Runs/failed-prod-run.md): Set up notifications to debug failed runs
- [What happens if the SQL in my query is bad or I get a database error?](https://docs.getdbt.com/faqs/Troubleshooting/sql-errors.md): Use error message and logs to debug
- [What if my source is in a different database to my target database?](https://docs.getdbt.com/faqs/Project/source-in-different-database.md): Use database property to define source in a diff database
- [What if my source is in a poorly named schema or table?](https://docs.getdbt.com/faqs/Project/source-has-bad-name.md): Use schema and identifier properities to define names
- [What materializations are available in dbt?](https://docs.getdbt.com/faqs/Models/available-materializations.md): dbt uses 4 materializations
- [What model configurations exist?](https://docs.getdbt.com/faqs/Models/available-configurations.md): Learning about model configurations
- [What parts of Jinja are dbt-specific?](https://docs.getdbt.com/faqs/Accounts/dbt-specific-jinja.md): You can check which Jinja functions are dbt-specific
- [What privileges does my database user need to use dbt?](https://docs.getdbt.com/faqs/Warehouse/database-privileges.md): Database privileges to use dbt
- [What should I name my profile?](https://docs.getdbt.com/faqs/Environments/profile-name.md): Use company name for profile name
- [What should I name my target?](https://docs.getdbt.com/faqs/Environments/target-names.md): Using targets to clarify development and production runs
- [What should my profiles.yml file look like for my warehouse?](https://docs.getdbt.com/faqs/Warehouse/sample-profiles.md): Go to Profile Set up to see the structure of a profile
- [What version of Python can I use?](https://docs.getdbt.com/faqs/Core/install-python-compatibility.md): Python versions supported with dbt Core
- [When should I run my data tests?](https://docs.getdbt.com/faqs/Tests/when-to-test.md): Run data tests in production or when writing new code
- [When should I use a UDF instead of a macro?](https://docs.getdbt.com/faqs/Project/udfs-vs-macros.md): Guidance on choosing between UDFs and macros
- [Where can I find my user id?](https://docs.getdbt.com/faqs/Accounts/find-user-id.md): Instructions on where to find your user id
- [Which docs should I use when writing Jinja or creating a macro?](https://docs.getdbt.com/faqs/Jinja/which-jinja-docs.md): Useful Jinja docs
- [Which materialization should I use for my model?](https://docs.getdbt.com/faqs/Project/which-materialization.md): Recommendations on materializations to use for models
- [Which SQL dialect should I write my models in? Or which SQL dialect does dbt use?](https://docs.getdbt.com/faqs/Models/sql-dialect.md): Use SQL dialect of your own database
- [Why am I getting an "account in use" error?](https://docs.getdbt.com/faqs/Accounts/git-account-in-use.md): What to do when you receive a Git account in use error
- [Why am I receiving a Runtime Error in my packages?](https://docs.getdbt.com/faqs/Troubleshooting/runtime-packages.yml.md): Update dbt_utils package in packages.yml file
- [Why are profiles stored outside of my project?](https://docs.getdbt.com/faqs/Project/separate-profile.md): Profiles stored outside version control
- [Why can't I just write DML in my transformations?](https://docs.getdbt.com/faqs/Project/why-not-write-dml.md): Using SQL in your transformations instead of DML.
- [Why dbt compile needs a data platform connection](https://docs.getdbt.com/faqs/Warehouse/db-connection-dbt-compile.md): `dbt compile` needs a data platform connection because the work it does depends on the current state of your warehouse
- [Why do I need to quote column names in Jinja?](https://docs.getdbt.com/faqs/Jinja/quoting-column-names.md): Use quotes to pass string
- [Why do model and source YAML files always start with `version: 2`?](https://docs.getdbt.com/faqs/Project/why-version-2.md): .yml file structure more extensible with version 2.
- [Why does my dbt output have so many macros in it?](https://docs.getdbt.com/faqs/Project/why-so-many-macros.md): Your dbt project includes many macros.
- [Why does the BigQuery OAuth application require scopes to Google Drive?](https://docs.getdbt.com/faqs/Warehouse/bq-oauth-drive-scope.md): Learn more about Google Drive scopes in the BigQuery OAuth application
- [Why doesn’t an indirectly referenced upstream public model appear in Explorer?](https://docs.getdbt.com/faqs/Project_ref/indirectly-reference-upstream-model.md): Learn why an indirectly referenced upstream public models don't appear in Explorer
- [Why is Run on Pull request grayed out?](https://docs.getdbt.com/faqs/Git/run-on-pull.md): Use the GitHub auth method to enable Rull on Pull request
- [Why would I want to impersonate a service account?](https://docs.getdbt.com/faqs/Warehouse/bq-impersonate-service-account-why.md): Build models using dedicated service account

## Fusion

- [About Fusion local installation Preview](https://docs.getdbt.com/docs/fusion/install-fusion.md): Install the Fusion engine locally to take data transformation to the next level.
- [About profiles.yml](https://docs.getdbt.com/docs/fusion/connect-data-platform-fusion/profiles.yml.md): The dbt profiles.yml file contains the connection details for your data warehouse.
- [About the dbt Fusion engine](https://docs.getdbt.com/docs/fusion/about-fusion.md): Fusion is the next-generation engine for dbt.
- [BigQuery setup Preview](https://docs.getdbt.com/docs/fusion/connect-data-platform-fusion/bigquery-setup.md): Read this guide to learn about the BigQuery warehouse setup in dbt Fusion.
- [Connection profiles](https://docs.getdbt.com/docs/fusion/connect-data-platform-fusion/connection-profiles.md): Configure the connection profile for your dbt project in Fusion.
- [Databricks setup Preview](https://docs.getdbt.com/docs/fusion/connect-data-platform-fusion/databricks-setup.md): Read this guide to learn about the Databricks warehouse setup in dbt Fusion.
- [dbt Fusion engine](https://docs.getdbt.com/docs/fusion.md): Fusion is the next-generation engine and development experience for dbt projects.
- [Fusion availability](https://docs.getdbt.com/docs/fusion/fusion-availability.md): Learn where the dbt Fusion engine is available.
- [New concepts](https://docs.getdbt.com/docs/fusion/new-concepts.md): New concepts and configurations you will encounter when you install the dbt Fusion engine.
- [Redshift setup Preview](https://docs.getdbt.com/docs/fusion/connect-data-platform-fusion/redshift-setup.md): Read this guide to learn about the Redshift warehouse setup in dbt Fusion.
- [Salesforce Data Cloud setup](https://docs.getdbt.com/docs/fusion/connect-data-platform-fusion/salesforce-data-cloud-setup.md): Read this guide to learn about the Salesforce Data Cloud warehouse setup in dbt.
- [Snowflake setup Preview](https://docs.getdbt.com/docs/fusion/connect-data-platform-fusion/snowflake-setup.md): Read this guide to learn about the Snowflake warehouse setup in dbt Fusion.
- [Supported features](https://docs.getdbt.com/docs/fusion/supported-features.md): Feature support and parity information for the dbt Fusion engine.

## Getting Started

- [dbt platform configuration checklist StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/configuration-checklist.md): Your to-do list for setting up your dbt platform account
- [dbt Quickstarts](https://docs.getdbt.com/docs/get-started-dbt.md): Begin your dbt journey by trying one of our quickstarts, which provides a step-by-step guide to help you set up  or  with a variety of data platforms.
- [What is dbt?](https://docs.getdbt.com/docs/introduction.md): dbt is the industry standard for data transformation.

## Guides

- [Airflow and dbt](https://docs.getdbt.com/guides/airflow-and-dbt-cloud.md): Introduction
- [Analyze your data in dbt](https://docs.getdbt.com/guides/analyze-your-data.md): Introduction
- [Browse our guides](https://docs.getdbt.com/guides.md)
- [Browse our guides](https://docs.getdbt.com/guides/_config.md): The dbt platform is the fastest and most reliable way to deploy dbt for scalable data transformation, while dbt Core powers open-source transformation workflows. Together, they provide a seamless analytics engineering experience. Explore our step-by-step guides, quickstart tutorials, and troubleshooting resources to get started with dbt and your data platform.
- [Build a data lakehouse with dbt Core and Dremio Cloud](https://docs.getdbt.com/guides/build-dremio-lakehouse.md): Learn how to build a data lakehouse with dbt Core and Dremio Cloud.
- [Build, test, document, and promote adapters](https://docs.getdbt.com/guides/adapter-creation.md): Create an adapter that connects dbt to you platform, and learn how to maintain and version that adapter.
- [Building dbt packages](https://docs.getdbt.com/guides/building-packages.md): When you have dbt code that might help others, you can create a package for dbt using a GitHub repository.
- [Coalesce dbt Fusion Engine in platform Quickstart Guide](https://docs.getdbt.com/guides/coalesce-fusion-platform-qs.md): Introduction
- [Create Datadog events from dbt results](https://docs.getdbt.com/guides/serverless-datadog.md): Configure a serverless app to add dbt events to Datadog logs.
- [Create new materializations](https://docs.getdbt.com/guides/create-new-materializations.md): Learn how to create your own materializations.
- [Customize dbt models database, schema, and alias](https://docs.getdbt.com/guides/customize-schema-alias.md): Learn how to properly adjust your generate_schema_name() and generate_alias_name() macros.
- [Customizing CI/CD with custom pipelines](https://docs.getdbt.com/guides/custom-cicd-pipelines.md): Learn the benefits of version-controlled analytics code and custom pipelines in dbt for enhanced code testing and workflow automation during the development process.
- [Debug errors](https://docs.getdbt.com/guides/debug-errors.md): Learn about errors and the art of debugging them.
- [Debug schema names](https://docs.getdbt.com/guides/debug-schema-names.md): Learn how to debug schema names when models build under unexpected schemas.
- [Get started with Continuous Integration tests](https://docs.getdbt.com/guides/set-up-ci.md): Implement a CI environment for safe project validation.
- [Integrate with dbt Semantic Layer using best practices](https://docs.getdbt.com/guides/sl-partner-integration-guide.md): Learn about partner integration guidelines, roadmap, and connectivity.
- [Legacy dbt Semantic Layer migration guide](https://docs.getdbt.com/guides/sl-migration.md): Learn how to migrate from the legacy dbt Semantic Layer to the latest one.
- [Leverage dbt to generate analytics and ML-ready pipelines with SQL and Python with Snowflake](https://docs.getdbt.com/guides/dbt-python-snowpark.md): Leverage dbt to generate analytics and ML-ready pipelines with SQL and Python with Snowflake
- [Migrate from dbt-spark to dbt-databricks](https://docs.getdbt.com/guides/migrate-from-spark-to-databricks.md): Learn how to migrate from dbt-spark to dbt-databricks.
- [Migrate from DDL, DML, and stored procedures](https://docs.getdbt.com/guides/migrate-from-stored-procedures.md): Learn how to transform from a historical codebase of mixed DDL and DML statements to dbt models, including tips and patterns for the shift from a procedural to a declarative approach in defining datasets.
- [Move from dbt Core to the dbt platform: Get started](https://docs.getdbt.com/guides/core-to-cloud-1.md): Learn how to move from dbt Core to the dbt platform and what you need to get started.
- [Move from dbt Core to the dbt platform: Optimization tips](https://docs.getdbt.com/guides/core-to-cloud-3.md): Use this guide to learn how to optimize your dbt experience and get answers to common questions.
- [Move from dbt Core to the dbt platform: What you need to know](https://docs.getdbt.com/guides/core-cloud-2.md): Use this guide to understand the considerations and methods you need to move from dbt Core to the dbt platform.
- [Optimize and troubleshoot dbt models on Databricks](https://docs.getdbt.com/guides/optimize-dbt-models-on-databricks.md): Learn more about optimizing and troubleshooting your dbt models on Databricks
- [Post to Microsoft Teams when a job finishes](https://docs.getdbt.com/guides/zapier-ms-teams.md): Use Zapier and dbt webhooks to post to Microsoft Teams when a job finishes running.
- [Post to Slack with error context when a job fails](https://docs.getdbt.com/guides/zapier-slack.md): Use a webhook or Slack message to trigger Zapier and post error context in Slack when a job fails.
- [Productionize your dbt Databricks project](https://docs.getdbt.com/guides/productionize-your-dbt-databricks-project.md): Learn how to deliver models to end users and use best practices to maintain production data.
- [Quickstart for dbt and Amazon Athena](https://docs.getdbt.com/guides/athena.md): Introduction
- [Quickstart for dbt and Azure Synapse Analytics](https://docs.getdbt.com/guides/azure-synapse-analytics.md): Introduction
- [Quickstart for dbt and BigQuery](https://docs.getdbt.com/guides/bigquery.md): Introduction
- [Quickstart for dbt and Databricks](https://docs.getdbt.com/guides/databricks.md): Introduction
- [Quickstart for dbt and Microsoft Fabric](https://docs.getdbt.com/guides/microsoft-fabric.md): Introduction
- [Quickstart for dbt and Redshift](https://docs.getdbt.com/guides/redshift.md): Introduction
- [Quickstart for dbt and Snowflake](https://docs.getdbt.com/guides/snowflake.md): Introduction
- [Quickstart for dbt and Starburst Galaxy](https://docs.getdbt.com/guides/starburst-galaxy.md): Introduction
- [Quickstart for dbt and Teradata](https://docs.getdbt.com/guides/teradata.md): Introduction
- [Quickstart for dbt Canvas](https://docs.getdbt.com/guides/canvas.md): Introduction
- [Quickstart for dbt Core from a manual install](https://docs.getdbt.com/guides/manual-install.md): Connecting your warehouse to dbt Core using the CLI.
- [Quickstart for dbt Core using DuckDB](https://docs.getdbt.com/guides/duckdb.md): Learn to use dbt Core using DuckDB.
- [Quickstart for the dbt Catalog workshop](https://docs.getdbt.com/guides/explorer-quickstart.md): Use this guide to build and define metrics, set up the dbt Semantic Layer, and query them using Google Sheets.
- [Quickstart for the dbt Fusion engine](https://docs.getdbt.com/guides/fusion.md): Introduction
- [Quickstart for the dbt Semantic Layer and Snowflake](https://docs.getdbt.com/guides/sl-snowflake-qs.md): Use this guide to build and define metrics, set up the dbt Semantic Layer, and query them using Google Sheets.
- [Quickstart with dbt Mesh](https://docs.getdbt.com/guides/mesh-qs.md): Introduction
- [Quickstart with MetricFlow time spine](https://docs.getdbt.com/guides/mf-time-spine.md): Introduction
- [Refactoring legacy SQL to dbt](https://docs.getdbt.com/guides/refactoring-legacy-sql.md): This guide walks through refactoring a long SQL query (perhaps from a stored procedure) into modular dbt data models.
- [Refresh a Mode dashboard when a job completes](https://docs.getdbt.com/guides/zapier-refresh-mode-report.md): Use Zapier to trigger a Mode dashboard refresh when a dbt job completes.
- [Refresh Tableau workbook with extracts after a job finishes](https://docs.getdbt.com/guides/zapier-refresh-tableau-workbook.md): Use Zapier to trigger a Tableau workbook refresh once a dbt job completes successfully.
- [Set up your dbt project with Databricks](https://docs.getdbt.com/guides/set-up-your-databricks-dbt-project.md): Learn more about setting up your dbt project with Databricks.
- [Trigger PagerDuty alarms when dbt jobs fail](https://docs.getdbt.com/guides/serverless-pagerduty.md): Use webhooks to configure a serverless app to trigger PagerDuty alarms.
- [Use Databricks workflows to run dbt jobs](https://docs.getdbt.com/guides/how-to-use-databricks-workflows-to-run-dbt-cloud-jobs.md): Learn how to use Databricks workflows to run dbt jobs
- [Use Jinja to improve your SQL code](https://docs.getdbt.com/guides/using-jinja.md): Learn how to improve your SQL code using Jinja.
- [Using BigQuery DataFrames with dbt Python models](https://docs.getdbt.com/guides/dbt-python-bigframes.md): Use this guide to help you set up dbt with BigQuery DataFrames (BigFrames).

## Navigation Options

- [navigation-options](https://docs.getdbt.com/navigation-options.md)

## Platform

- [About Canvas EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/canvas.md): dbt Canvas enables you to quickly create and visualize dbt models through a visual, drag-and-drop experience inside of dbt.
- [About cost management Private previewEnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/cost-management.md): Manage your data warehouse costs in dbt
- [About dbt Copilot StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/dbt-copilot.md): dbt Copilot is a powerful AI-powered assistant designed to accelerate your analytics workflows throughout your entire ADLC.
- [About dbt setup](https://docs.getdbt.com/docs/cloud/about-cloud-setup.md): Configuration settings for dbt.
- [About Studio IDE](https://docs.getdbt.com/docs/cloud/about-cloud/about-cloud-ide.md): about dbt Studio Integrated Development Environment
- [About the Studio IDE](https://docs.getdbt.com/docs/cloud/dbt-cloud-ide/develop-in-the-cloud.md): Develop, test, run, and build in the Studio IDE. You can compile dbt code into SQL and run it against your database directly
- [Access, Regions, & IP addresses](https://docs.getdbt.com/docs/cloud/about-cloud/access-regions-ip-addresses.md): Available regions and ip addresses
- [Billing](https://docs.getdbt.com/docs/cloud/billing.md): dbt billing information.
- [Build with dbt Copilot EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/build-canvas-copilot.md): Use dbt Copilot to build visual models in Canvas with natural language prompts
- [Change your dbt theme](https://docs.getdbt.com/docs/cloud/about-cloud/change-your-dbt-cloud-theme.md): Learn about theme switching in dbt
- [Configure and use the dbt CLI](https://docs.getdbt.com/docs/cloud/configure-cloud-cli.md): Instructions on how to configure the dbt CLI
- [Copilot chat in Studio StarterEnterpriseEnterprise+](https://docs.getdbt.com/docs/cloud/copilot-chat-in-studio.md): Use the Copilot chat feature in the Studio to generate SQL using your input and the context of the active project.
- [Copilot style guide](https://docs.getdbt.com/docs/cloud/copilot-styleguide.md): Use the Copilot `dbt-styleguide.md` file for best practices and naming conventions in dbt projects.
- [dbt Architecture](https://docs.getdbt.com/docs/cloud/about-cloud/architecture.md): Information about the architecture, communication, and security of dbt
- [dbt Copilot FAQs](https://docs.getdbt.com/docs/cloud/dbt-copilot-faqs.md): Answers to common questions about dbt Copilot.
- [Develop with dbt](https://docs.getdbt.com/docs/cloud/about-develop-dbt.md): Learn how to develop your dbt projects using dbt.
- [Develop with dbt Copilot StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/dbt-cloud-ide/develop-copilot.md): Use dbt Copilot to generate documentation, tests, semantic models, and SQL code from scratch, giving you the flexibility to modify or fix generated code.
- [Edit and create dbt models EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/use-canvas.md): Access and use Canvas to create or edit dbt models through a visual, drag-and-drop experience inside of dbt.
- [Enable dbt Copilot StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/enable-dbt-copilot.md): Enable dbt Copilot, an AI-powered assistant, in dbt to speed up your development.
- [Fix deprecation warnings](https://docs.getdbt.com/docs/cloud/dbt-cloud-ide/autofix-deprecations.md): Learn how you can use the autofix tool in the Studio IDE to update project code.
- [Git commit signing EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/dbt-cloud-ide/git-commit-signing.md): Learn how to sign your Git commits when using the IDE for development.
- [IDE user interface](https://docs.getdbt.com/docs/cloud/dbt-cloud-ide/ide-user-interface.md): Develop, test, run, and build in the Studio IDE. With the Studio IDE, you can compile dbt code into SQL and run it against your database directly
- [Install dbt CLI](https://docs.getdbt.com/docs/cloud/cloud-cli-installation.md): Instructions for installing and configuring dbt CLI
- [Lint and format your code](https://docs.getdbt.com/docs/cloud/dbt-cloud-ide/lint-format.md): Integrate with popular linters and formatters like SQL Fluff, sqlfmt, Black, and Prettier."
- [Navigate the interface EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/canvas-interface.md): The dbt Canvas interface contains an operator toolbar, operators, and a canvas to help you access and transform data through a seamless drag-and-drop dbt model creation experience in dbt.
- [Studio IDE keyboard shortcuts](https://docs.getdbt.com/docs/cloud/dbt-cloud-ide/keyboard-shortcuts.md): Learn about the keyboard shortcuts available in the Studio IDE.
- [Supported browsers](https://docs.getdbt.com/docs/cloud/about-cloud/browsers.md): dbt supports the latest browsers like Chrome and Firefox.
- [Tenancy](https://docs.getdbt.com/docs/cloud/about-cloud/tenancy.md): Information about single tenant and multi-tenant dbt instances
- [The dbt platform features](https://docs.getdbt.com/docs/cloud/about-cloud/dbt-cloud-features.md): Explore dbt's features and learn why the dbt platform is the fastest way to deploy dbt
- [Use dbt Copilot StarterEnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/use-dbt-copilot.md): Use dbt Copilot to generate documentation, tests, semantic models, and SQL code from scratch, giving you the flexibility to modify or fix generated code.
- [Using defer in dbt](https://docs.getdbt.com/docs/cloud/about-cloud-develop-defer.md): Learn how to leverage defer to prod when developing with dbt.

## Reference

- [.dbtignore](https://docs.getdbt.com/reference/dbtignore.md): You can create a .dbtignore file in the root of your dbt project to specify files that should be entirely ignored by dbt. The file behaves like a .gitignore file, using the same syntax. Files and subdirectories matching the pattern will not be read, parsed, or otherwise detected by dbt—as if they didn't exist.
- [About adapter object](https://docs.getdbt.com/reference/dbt-jinja-functions/adapter.md): Wrap the internal database adapter with the Jinja object `adapter`.
- [About adapter-specific behavior changes](https://docs.getdbt.com/reference/global-configs/adapter-behavior-changes.md): Adapter-specific behavior changes
- [About as_bool filter](https://docs.getdbt.com/reference/dbt-jinja-functions/as_bool.md): Use this filter to coerce a Jinja output into boolean value.
- [About as_native filter](https://docs.getdbt.com/reference/dbt-jinja-functions/as_native.md): Use this filter to coerce Jinja-compiled output into its native python.
- [About as_number filter](https://docs.getdbt.com/reference/dbt-jinja-functions/as_number.md): Use this filter to convert Jinja-compiled output to a numeric value..
- [About builtins Jinja variable](https://docs.getdbt.com/reference/dbt-jinja-functions/builtins.md): Read this guide to understand the builtins Jinja variable in dbt.
- [About config property](https://docs.getdbt.com/reference/resource-properties/config.md): <Tabs
- [About config variable](https://docs.getdbt.com/reference/dbt-jinja-functions/config.md): Read this guide to understand the config Jinja function in dbt.
- [About data tests property](https://docs.getdbt.com/reference/resource-properties/data-tests.md): Reference guide for the resource properties available for data tests in dbt.
- [About dbt --version](https://docs.getdbt.com/reference/commands/version.md): The --version command-line flag returns information about the currently installed version of  or the . This flag is not supported when invoking dbt in other  runtimes (for example, the IDE or scheduled runs).
- [About dbt artifacts](https://docs.getdbt.com/reference/artifacts/dbt-artifacts.md): With every invocation, dbt generates and saves one or more artifacts. Several of these are  files (semanticmanifest.json, manifest.json, catalog.json, runresults.json, and sources.json) that are used to power:
- [About dbt build command](https://docs.getdbt.com/reference/commands/build.md): The dbt build command will:
- [About dbt clean command](https://docs.getdbt.com/reference/commands/clean.md): dbt clean is a utility function that deletes the paths specified within the clean-targets list in the dbt_project.yml file. It helps by removing unnecessary files or directories generated during the execution of other dbt commands, ensuring a clean state for the project.
- [About dbt clone command](https://docs.getdbt.com/reference/commands/clone.md): The dbt clone command clones selected nodes from the specified state to the target schema(s). This command makes use of the clone materialization:
- [About dbt compile command](https://docs.getdbt.com/reference/commands/compile.md): The dbt compile command creates executable SQL from model, test, and analysis files.
- [About dbt debug command](https://docs.getdbt.com/reference/commands/debug.md): Use dbt debug to test database connections and check system setup.
- [About dbt deps command](https://docs.getdbt.com/reference/commands/deps.md): dbt deps pulls the most recent version of the dependencies listed in your packages.yml from git. See Package-Management for more information.
- [About dbt docs commands](https://docs.getdbt.com/reference/commands/cmd-docs.md): Generate and serve the docs for your dbt project.
- [About dbt environment command](https://docs.getdbt.com/reference/commands/dbt-environment.md): The dbt environment command enables you to interact with your  environment. Use the command for:
- [About dbt init command](https://docs.getdbt.com/reference/commands/init.md): dbt init helps get you started using !
- [About dbt invocation command](https://docs.getdbt.com/reference/commands/invocation.md): The dbt invocation command is available in the  and allows you to:
- [About dbt ls (list) command](https://docs.getdbt.com/reference/commands/list.md): Read this guide on how dbt's ls (list) command can be used to list resources in your dbt project.
- [About dbt parse command](https://docs.getdbt.com/reference/commands/parse.md): Read this guide on how dbt's parse command can be used to parse your dbt project and write detailed timing information.
- [About dbt retry command](https://docs.getdbt.com/reference/commands/retry.md): dbt retry re-executes the last dbt command from the node point of failure.
- [About dbt rpc command](https://docs.getdbt.com/reference/commands/rpc.md): Remote Procedure Call (rpc) dbt server compiles and runs queries, and provides methods that enable you to list and terminate running processes. 
- [About dbt run command](https://docs.getdbt.com/reference/commands/run.md): The dbt run command executes your compiled SQL models against a target database.
- [About dbt run-operation command](https://docs.getdbt.com/reference/commands/run-operation.md): Read this guide on how dbt's run-operation command can be used to invoke a macro.
- [About dbt seed command](https://docs.getdbt.com/reference/commands/seed.md): The dbt seed command will load csv files located in the seed-paths directory of your dbt project into your .
- [About dbt show command](https://docs.getdbt.com/reference/commands/show.md): Use dbt show to:
- [About dbt snapshot command](https://docs.getdbt.com/reference/commands/snapshot.md): The dbt snapshot command executes the Snapshots defined in your project.
- [About dbt source command](https://docs.getdbt.com/reference/commands/source.md): The dbt source command provides subcommands that are useful when working with source data. This command provides one subcommand, dbt source freshness.
- [About dbt test command](https://docs.getdbt.com/reference/commands/test.md): dbt test runs data tests defined on models, sources, snapshots, and seeds and unit tests defined on SQL models. It expects that you have already created those resources through the appropriate commands.
- [About dbt_project.yml context](https://docs.getdbt.com/reference/dbt-jinja-functions/dbt-project-yml-context.md): The context methods and variables available when configuring resources in the dbt_project.yml file.
- [About dbt_version variable](https://docs.getdbt.com/reference/dbt-jinja-functions/dbt_version.md): Read this guide to understand the dbt_version Jinja function in dbt.
- [About debug macro](https://docs.getdbt.com/reference/dbt-jinja-functions/debug-method.md): The `{{ debug() }}` macro will open an iPython debugger.
- [About dispatch config](https://docs.getdbt.com/reference/dbt-jinja-functions/dispatch.md): dbt extends functionality across data platforms using multiple dispatch.
- [About doc function](https://docs.getdbt.com/reference/dbt-jinja-functions/doc.md): Use the `doc` to reference docs blocks in description fields.
- [About env_var function](https://docs.getdbt.com/reference/dbt-jinja-functions/env_var.md): Incorporate environment variables using `en_var` function.
- [About exceptions namespace](https://docs.getdbt.com/reference/dbt-jinja-functions/exceptions.md): Raise warnings/errors with the `exceptions` namespace.
- [About execute variable](https://docs.getdbt.com/reference/dbt-jinja-functions/execute.md): Use `execute` to return True when dbt is in 'execute' mode.
- [About flags (global configs)](https://docs.getdbt.com/reference/global-configs/about-global-configs.md): In dbt, "flags" (also called "global configs") are configurations for fine-tuning how dbt runs your project. They differ from resource-specific configs that tell dbt about what to run.
- [About flags variable](https://docs.getdbt.com/reference/dbt-jinja-functions/flags.md): The `flags` variable contains values of flags provided on the cli.
- [About fromjson context method](https://docs.getdbt.com/reference/dbt-jinja-functions/fromjson.md): Deserialize a JSON string into python with `fromjson` context method.
- [About fromyaml context method](https://docs.getdbt.com/reference/dbt-jinja-functions/fromyaml.md): Deserialize a YAML string into python with `fromyaml` context method.
- [About graph context variable](https://docs.getdbt.com/reference/dbt-jinja-functions/graph.md): The `graph` context variable contains info about nodes in your project.
- [About invocation_id](https://docs.getdbt.com/reference/dbt-jinja-functions/invocation_id.md): The `invocation_id` outputs a UUID generated for this dbt command.
- [About local_md5 context variable](https://docs.getdbt.com/reference/dbt-jinja-functions/local_md5.md): Calculate an MD5 hash of a string with `local_md5` context variable.
- [About model object](https://docs.getdbt.com/reference/dbt-jinja-functions/model.md): `model` is the dbt graph object (or node) for the current model.
- [About model schema](https://docs.getdbt.com/reference/dbt-jinja-functions/schema.md): The schema that the model is configured to be materialized in.
- [About modules variable](https://docs.getdbt.com/reference/dbt-jinja-functions/modules.md): `modules` Jinja variables has useful Python modules to operate data.
- [About on-run-end context variable](https://docs.getdbt.com/reference/dbt-jinja-functions/on-run-end-context.md): Use these variables in the context for `on-run-end` hooks.
- [About print function](https://docs.getdbt.com/reference/dbt-jinja-functions/print.md): Use the `print()` to print messages to the log file and stdout.
- [About profiles.yml context](https://docs.getdbt.com/reference/dbt-jinja-functions/profiles-yml-context.md): Use these context methods to configure resources in `profiles.yml` file.
- [About project_name context variable](https://docs.getdbt.com/reference/dbt-jinja-functions/project_name.md): Read this guide to understand the project_name Jinja function in dbt.
- [About properties.yml context](https://docs.getdbt.com/reference/dbt-jinja-functions/dbt-properties-yml-context.md): The context methods and variables available when configuring resources in a properties.yml file.
- [About ref function](https://docs.getdbt.com/reference/dbt-jinja-functions/ref.md): Read this guide to understand the ref Jinja function in dbt.
- [About References](https://docs.getdbt.com/reference/references-overview.md): Connect dbt to any data platform in the dbt platform or dbt Core, using a dedicated adapter plugin
- [About return function](https://docs.getdbt.com/reference/dbt-jinja-functions/return.md): Read this guide to understand the return Jinja function in dbt.
- [About run_query macro](https://docs.getdbt.com/reference/dbt-jinja-functions/run_query.md): Use `run_query` macro to run queries and fetch results.
- [About run_started_at variable](https://docs.getdbt.com/reference/dbt-jinja-functions/run_started_at.md): Use `run_started_at` to output the timestamp the run started.
- [About schemas variable](https://docs.getdbt.com/reference/dbt-jinja-functions/schemas.md): A list of schemas where dbt built objects during the current run.
- [About selected_resources context variable](https://docs.getdbt.com/reference/dbt-jinja-functions/selected_resources.md): Contains a list of all the nodes selected by current dbt command.
- [About set context method](https://docs.getdbt.com/reference/dbt-jinja-functions/set.md): Converts any iterable to a sequence of iterable and unique elements.
- [About source function](https://docs.getdbt.com/reference/dbt-jinja-functions/source.md): Read this guide to understand the source Jinja function in dbt.
- [About state in dbt](https://docs.getdbt.com/reference/node-selection/state-selection.md): dbt operations are stateless and idempotent, but artifacts enable state-based features like slim CI and deferral.
- [About statement blocks](https://docs.getdbt.com/reference/dbt-jinja-functions/statement-blocks.md): SQL queries that hit database and return results to your Jinja context.
- [About target variables](https://docs.getdbt.com/reference/dbt-jinja-functions/target.md): The `target` variable contains information about your connection to the warehouse.
- [about this](https://docs.getdbt.com/reference/dbt-jinja-functions/this.md): Represents the current model in the database.
- [About thread_id](https://docs.getdbt.com/reference/dbt-jinja-functions/thread_id.md): The `thread_id` outputs an identifier for the current Python thread.
- [About tojson context method](https://docs.getdbt.com/reference/dbt-jinja-functions/tojson.md): Use this context method to serialize a Python object primitive.
- [About toyaml context method](https://docs.getdbt.com/reference/dbt-jinja-functions/toyaml.md): Used to serialize a Python object primitive.
- [About unit tests property](https://docs.getdbt.com/reference/resource-properties/unit-tests.md): Unit tests validate your SQL modeling logic on a small set of static inputs before you materialize your full model in production. They support a test-driven development approach, improving both the efficiency of developers and reliability of code.
- [About var function](https://docs.getdbt.com/reference/dbt-jinja-functions/var.md): Pass variables from `dbt_project.yml` file into models.
- [About zip context method](https://docs.getdbt.com/reference/dbt-jinja-functions/zip.md): Use this context method to return an iterator of tuples.
- [access](https://docs.getdbt.com/reference/resource-configs/access.md): .yml'>
- [Advanced configuration usage](https://docs.getdbt.com/reference/advanced-config-usage.md): Alternative config block syntax
- [alias](https://docs.getdbt.com/reference/resource-configs/alias.md): Aliasing a resource lets you give it a custom name in the database instead of using the filename.
- [Amazon Athena configurations](https://docs.getdbt.com/reference/resource-configs/athena-configs.md): Reference article for the Amazon Athena adapter for dbt Core and the dbt platform.
- [Amazon Redshift adapter behavior changes](https://docs.getdbt.com/reference/global-configs/redshift-changes.md): The restrictdirectpgcatalogaccess flag
- [Analysis properties](https://docs.getdbt.com/reference/analysis-properties.md): We recommend you define analysis properties in your analyses/ directory, which is illustrated in the analysis-paths configuration.
- [analysis-paths](https://docs.getdbt.com/reference/project-configs/analysis-paths.md): Read this guide to understand the analysis-paths configuration in dbt.
- [anchors](https://docs.getdbt.com/reference/resource-properties/anchors.md): Definition
- [Anonymous usage stats](https://docs.getdbt.com/reference/global-configs/usage-stats.md): dbt Labs is on a mission to build the best version of dbt possible, and a crucial part of that is understanding how users work with dbt. To this end, we've added some simple event tracking (or telemetry) to dbt using Snowplow. Importantly, we do not track credentials, raw model contents, or model names: we consider these private, and frankly none of our business.
- [Apache Spark configurations](https://docs.getdbt.com/reference/resource-configs/spark-configs.md): Apache Spark Configurations - Read this in-depth guide to learn about configurations in dbt.
- [arguments (for functions)](https://docs.getdbt.com/reference/resource-properties/function-arguments.md): .yml'>
- [arguments (for macros)](https://docs.getdbt.com/reference/resource-properties/arguments.md): .yml'>
- [asset-paths](https://docs.getdbt.com/reference/project-configs/asset-paths.md): Read this guide to understand the asset-paths configuration in dbt.
- [AWS Glue configurations](https://docs.getdbt.com/reference/resource-configs/glue-configs.md): AWS Glue Configurations - Read this in-depth guide to learn about configurations in dbt.
- [batch_size](https://docs.getdbt.com/reference/resource-configs/batch-size.md): dbt uses `batch_size` to determine how large batches are when running a microbatch incremental model.
- [begin](https://docs.getdbt.com/reference/resource-configs/begin.md): dbt uses `begin` to determine when a microbatch incremental model should begin from. When defined on a micorbatch incremental model, `begin` is used as the lower time bound when the model is built for the first time or fully refreshed.
- [Behavior changes](https://docs.getdbt.com/reference/global-configs/behavior-changes.md): Most flags exist to configure runtime behaviors with multiple valid choices. The right choice may vary based on the environment, user preference, or the specific invocation.
- [BigQuery configurations](https://docs.getdbt.com/reference/resource-configs/bigquery-configs.md): Reference guide for Big Query configurations in dbt.
- [Cache](https://docs.getdbt.com/reference/global-configs/cache.md): Cache population
- [Catalog JSON file](https://docs.getdbt.com/reference/artifacts/catalog-json.md): Current schema: v1
- [Caveats to state comparison](https://docs.getdbt.com/reference/node-selection/state-comparison-caveats.md): Learn about caveats to state comparison in dbt.
- [check_cols](https://docs.getdbt.com/reference/resource-configs/check_cols.md): Read this guide to understand the check_cols configuration in dbt.
- [Checking version compatibility](https://docs.getdbt.com/reference/global-configs/version-compatibility.md): For the first several years of 's development, breaking changes were more common. For this reason, we encouraged setting dbt version requirements &mdash; especially if they use features that are newer or which may break in future versions of . By default, if you run a project with an incompatible dbt version, dbt will raise an error.
- [clean-targets](https://docs.getdbt.com/reference/project-configs/clean-targets.md): Definition
- [ClickHouse configurations](https://docs.getdbt.com/reference/resource-configs/clickhouse-configs.md): Read this guide to understand ClickHouse configurations in dbt.
- [Cloudera Hive configurations](https://docs.getdbt.com/reference/resource-configs/hive-configs.md): Cloudera Hive Configurations - Read this in-depth guide to learn about configurations in dbt.
- [Cloudera Impala configurations](https://docs.getdbt.com/reference/resource-configs/impala-configs.md): Impala Configs - Read this in-depth guide to learn about configurations in dbt.
- [column_types](https://docs.getdbt.com/reference/resource-configs/column_types.md): Description
- [columns](https://docs.getdbt.com/reference/resource-properties/columns.md): <Tabs
- [Command line options](https://docs.getdbt.com/reference/global-configs/command-line-options.md): For consistency, command-line interface (CLI) flags should come right after the dbt prefix and its subcommands. This includes "global" flags (supported for all commands). For a list of all  flags you can set, refer to Available flags. When set, CLI flags override environment variables and project flags.
- [concurrent_batches](https://docs.getdbt.com/reference/resource-properties/concurrent_batches.md): Learn about concurrent_batches in dbt.
- [config-version](https://docs.getdbt.com/reference/project-configs/config-version.md): Read this guide to understand the config-version configuration in dbt.
- [Configurations and properties, what are they?](https://docs.getdbt.com/reference/configs-and-properties.md): This page explains the difference between properties and configurations in dbt.
- [Configure state selection](https://docs.getdbt.com/reference/node-selection/configure-state.md): Learn how to configure state selection in dbt.
- [Configuring quoting in projects](https://docs.getdbt.com/reference/project-configs/quoting.md): Read this guide to understand the quoting configuration in dbt.
- [Configuring quoting in sources](https://docs.getdbt.com/reference/resource-properties/quoting.md): .yml'>
- [constraints](https://docs.getdbt.com/reference/resource-properties/constraints.md): Constraints are a feature of many data platforms. When specified, the platform will perform additional validation on data as it is being populated in a new table or inserted into a preexisting table. If the validation fails, the table creation or update fails, the operation is rolled back, and you will see a clear error message.
- [contract](https://docs.getdbt.com/reference/resource-configs/contract.md): When the contract configuration is enforced, dbt will ensure that your model's returned dataset exactly matches the attributes you have defined in yaml, such as name and data_type, as well as any additional constraints supported by the data platform.
- [Cross-database macros](https://docs.getdbt.com/reference/dbt-jinja-functions/cross-database-macros.md): Read this guide to understand cross-database macros in dbt.
- [Data test configurations](https://docs.getdbt.com/reference/data-test-configs.md): Read this guide to learn about using data test configurations in dbt.
- [database](https://docs.getdbt.com/reference/resource-configs/database.md): Override the default database when dbt creates resources in your data platform.
- [Database permissions](https://docs.getdbt.com/reference/database-permissions/about-database-permissions.md): Database permissions are access rights and privileges granted to users or roles within a database management system.
- [Databricks adapter behavior changes](https://docs.getdbt.com/reference/global-configs/databricks-changes.md): The following are the current behavior change flags that are specific to dbt-databricks:
- [Databricks configurations](https://docs.getdbt.com/reference/resource-configs/databricks-configs.md): Configuring tables
- [Databricks permissions](https://docs.getdbt.com/reference/database-permissions/databricks-permissions.md): In Databricks, permissions are used to control who can perform certain actions on different database objects. Use SQL statements to manage permissions in a Databricks database.
- [dbt Classes](https://docs.getdbt.com/reference/dbt-classes.md): dbt has a number of classes it uses to represent objects in a , parts of a dbt project, and the results of a command.
- [dbt Command reference](https://docs.getdbt.com/reference/dbt-commands.md): You can run dbt using the following tools:
- [dbt Jinja functions](https://docs.getdbt.com/reference/dbt-jinja-functions.md): In addition to the standard Jinja library, we've added additional functions and variables to the Jinja context that are useful when working with a dbt project.
- [dbt_project.yml](https://docs.getdbt.com/reference/dbt_project.yml.md): Reference guide for configuring the dbt_project.yml file.
- [dbt_valid_to_current](https://docs.getdbt.com/reference/resource-configs/dbt_valid_to_current.md): Use the `dbt_valid_to_current` config to set a custom indicator for the value of `dbt_valid_to` in current snapshot records
- [Defer](https://docs.getdbt.com/reference/node-selection/defer.md): Defer is a powerful feature that makes it possible to run a subset of models or tests in a sandbox environment without having to first build their upstream parents. This can save time and computational resources when you want to test a small number of models in a large project.
- [Define configs](https://docs.getdbt.com/reference/define-configs.md): Learn how to define configurations for your resources in a dbt project
- [Define properties](https://docs.getdbt.com/reference/define-properties.md): Learn how to define properties for your resources in a properties.yml file
- [Defining a database source property](https://docs.getdbt.com/reference/resource-properties/database.md): .yml'>
- [Defining a schema source property](https://docs.getdbt.com/reference/resource-properties/schema.md): .yml'>
- [delimiter](https://docs.getdbt.com/reference/resource-configs/delimiter.md): Definition
- [deprecation_date](https://docs.getdbt.com/reference/resource-properties/deprecation_date.md): .yml'>
- [Deprecations](https://docs.getdbt.com/reference/deprecations.md): Deprecated functionality still works in the v1.10 release, but it is no longer supported and will be removed in a future version.
- [description](https://docs.getdbt.com/reference/resource-properties/description.md): This guide explains how to use the description key to add YAML descriptions to dbt resources (models, sources, seeds) using markdown and Jinja for better documentation.
- [dispatch (config)](https://docs.getdbt.com/reference/project-configs/dispatch-config.md): Read this guide to understand the dispatch configuration in dbt.
- [docs](https://docs.getdbt.com/reference/resource-configs/docs.md): Docs - Read this in-depth guide to learn about configurations in dbt.
- [docs-paths](https://docs.getdbt.com/reference/project-configs/docs-paths.md): Read this guide to understand the docs-paths configuration in dbt.
- [Doris/SelectDB configurations](https://docs.getdbt.com/reference/resource-configs/doris-configs.md): Doris/SelectDB Configurations - Read this in-depth guide to learn about configurations in dbt.
- [DuckDB configurations](https://docs.getdbt.com/reference/resource-configs/duckdb-configs.md): Profile
- [enabled](https://docs.getdbt.com/reference/resource-configs/enabled.md): Enabled - Read this in-depth guide to learn about configurations in dbt.
- [Environment variable configs](https://docs.getdbt.com/reference/global-configs/environment-variable-configs.md): Environment variables contain a DBT_ prefix. For a list of all dbt environment variables you can set, refer to Available flags.
- [event_time](https://docs.getdbt.com/reference/resource-configs/event-time.md): dbt uses event_time to understand when an event occurred. When defined, event_time enables microbatch incremental models, the sample flag, and more refined comparison of datasets during Advanced CI.
- [Events and logs](https://docs.getdbt.com/reference/events-logging.md): As dbt runs, it generates events. The most common way to see those events is as log messages, written in real time to two places:
- [Exclude models from your run](https://docs.getdbt.com/reference/node-selection/exclude.md): Excluding models
- [Exit codes](https://docs.getdbt.com/reference/exit-codes.md): When dbt exits, it will return an exit code of either 0, 1, or 2.
- [Exposure properties](https://docs.getdbt.com/reference/exposure-properties.md): Read this guide to understand exposure properties in dbt.
- [external](https://docs.getdbt.com/reference/resource-properties/external.md): .yml'>
- [fail_calc](https://docs.getdbt.com/reference/resource-configs/fail_calc.md): Test queries are written to return a set of failing records, ones not matching the expectation or assertion declared by that test: duplicate records, null values, etc.
- [Failing fast](https://docs.getdbt.com/reference/global-configs/failing-fast.md): Supply the -x or --fail-fast flag to dbt run to make dbt exit immediately if a single resource fails to build. If other models are in-progress when the first model fails, then dbt will terminate the connections for these still-running models.
- [Firebolt configurations](https://docs.getdbt.com/reference/resource-configs/firebolt-configs.md): Setting quote_columns
- [freshness](https://docs.getdbt.com/reference/resource-properties/freshness.md): .yml'>
- [freshness Private previewEnterpriseEnterprise +](https://docs.getdbt.com/reference/resource-configs/freshness.md): Read this guide to understand the `freshness` configuration in dbt.
- [full_refresh](https://docs.getdbt.com/reference/resource-configs/full_refresh.md): Set the full_refresh config for models and other resources in dbt.
- [Function configurations](https://docs.getdbt.com/reference/function-configs.md): Read this guide to learn about using function configurations in dbt.
- [Function properties](https://docs.getdbt.com/reference/function-properties.md): Function properties can be declared in .yml files under a functions key.
- [function-paths](https://docs.getdbt.com/reference/project-configs/function-paths.md): Definition
- [grants](https://docs.getdbt.com/reference/resource-configs/grants.md): You can manage access to the datasets you're producing with dbt by using grants. To implement these permissions, define grants as resource configs on each model, seed, or snapshot. Define the default grants that apply to the entire project in your dbt_project.yml, and define model-specific grants within each model's SQL or YAML file.
- [Graph operators](https://docs.getdbt.com/reference/node-selection/graph-operators.md): The "plus" operator
- [Greenplum configurations](https://docs.getdbt.com/reference/resource-configs/greenplum-configs.md): Greenplum Configurations - Read this in-depth guide to learn about configurations in dbt.
- [group](https://docs.getdbt.com/reference/resource-configs/group.md): <Tabs
- [hard_deletes](https://docs.getdbt.com/reference/resource-configs/hard-deletes.md): Use the `hard_deletes` config to control how deleted rows are tracked in your snapshot table.
- [IBM Netezza configurations](https://docs.getdbt.com/reference/resource-configs/ibm-netezza-config.md): Instance requirements
- [IBM watsonx.data Presto configurations](https://docs.getdbt.com/reference/resource-configs/watsonx-presto-config.md): Instance requirements
- [IBM watsonx.data Spark configurations](https://docs.getdbt.com/reference/resource-configs/watsonx-spark-config.md): Instance requirements
- [identifier](https://docs.getdbt.com/reference/resource-properties/identifier.md): .yml'>
- [Indirect selection](https://docs.getdbt.com/reference/global-configs/indirect-selection.md): Use the --indirect-selection flag to dbt test or dbt build to configure which tests to run for the nodes you specify. You can set this as a CLI flag or an environment variable. In dbt Core, you can also configure user configurations in YAML selectors or in the flags: block of dbt_project.yml, which sets project-level flags.
- [Infer configurations](https://docs.getdbt.com/reference/resource-configs/infer-configs.md): Read this guide to understand how to configure Infer with dbt.
- [Input for unit tests](https://docs.getdbt.com/reference/resource-properties/unit-test-input.md): Use inputs in your unit tests to reference a specific model or source for the test:
- [invalidate_hard_deletes legacy](https://docs.getdbt.com/reference/resource-configs/invalidate_hard_deletes.md): Invalidate_hard_deletes - Read this in-depth guide to learn about configurations in dbt.
- [JSON artifacts](https://docs.getdbt.com/reference/global-configs/json-artifacts.md): Write JSON artifacts
- [latest_version](https://docs.getdbt.com/reference/resource-properties/latest_version.md): .yml'>
- [Legacy snapshot configuration legacy](https://docs.getdbt.com/reference/resource-configs/snapshots-jinja-legacy.md): Read about how to configure snapshots using legacy Jinja blocks
- [limit](https://docs.getdbt.com/reference/resource-configs/limit.md): Limit the number of failures that will be returned by a test query. We recommend using this config when working with large datasets and storing failures in the database.
- [loader](https://docs.getdbt.com/reference/resource-properties/loader.md): .yml'>
- [log](https://docs.getdbt.com/reference/dbt-jinja-functions/log.md): Learn more about the log Jinja function in dbt.
- [Logs](https://docs.getdbt.com/reference/global-configs/logs.md): Log formatting
- [lookback](https://docs.getdbt.com/reference/resource-configs/lookback.md): Configure `lookback` to determine how many 'batches' of `batch_size` to reprocess when a dbt microbatch incremental model runs incrementally
- [Macro properties](https://docs.getdbt.com/reference/macro-properties.md): Macro properties can be declared in any properties.yml file.
- [macro-paths](https://docs.getdbt.com/reference/project-configs/macro-paths.md): Read this guide to understand the macro-paths configuration in dbt.
- [Manifest JSON file](https://docs.getdbt.com/reference/artifacts/manifest-json.md): Produced by: Any command that parses your project. This includes all commands except deps, clean, debug, init
- [Materialize configurations](https://docs.getdbt.com/reference/resource-configs/materialize-configs.md): Materialize Configurations- Read this in-depth guide to learn about configurations in dbt.
- [materialized](https://docs.getdbt.com/reference/resource-configs/materialized.md): Materialized - Read this in-depth guide to learn about materializations in dbt.
- [meta](https://docs.getdbt.com/reference/resource-configs/meta.md): <Tabs
- [Microsoft Azure Synapse DWH configurations](https://docs.getdbt.com/reference/resource-configs/azuresynapse-configs.md): All configuration options for the Microsoft SQL Server adapter also apply to this adapter.
- [Microsoft Fabric Data Warehouse configurations](https://docs.getdbt.com/reference/resource-configs/fabric-configs.md): Materializations
- [Microsoft Fabric Spark configurations](https://docs.getdbt.com/reference/resource-configs/fabricspark-configs.md): Microsoft Fabric Spark Configurations - Read this in-depth guide to learn about configurations in dbt.
- [Microsoft SQL Server configurations](https://docs.getdbt.com/reference/resource-configs/mssql-configs.md): Materializations
- [MindsDB configurations](https://docs.getdbt.com/reference/resource-configs/mindsdb-configs.md): Authentication
- [Model configurations](https://docs.getdbt.com/reference/model-configs.md): Read this guide to understand model configurations in dbt.
- [Model properties](https://docs.getdbt.com/reference/model-properties.md): Models properties can be declared in .yml files in your models/ directory (as defined by the model-paths config).
- [model_name](https://docs.getdbt.com/reference/resource-properties/model_name.md): .yml'>
- [model-paths](https://docs.getdbt.com/reference/project-configs/model-paths.md): Definition
- [name](https://docs.getdbt.com/reference/project-configs/name.md): Read this guide to understand the name configuration in dbt.
- [name](https://docs.getdbt.com/reference/resource-properties/name.md): name
- [No specific configurations for this adapter](https://docs.getdbt.com/reference/resource-configs/no-configs.md): If you were guided to this page from a data platform setup article, it most likely means:
- [Node selector methods](https://docs.getdbt.com/reference/node-selection/methods.md): Selector methods return all resources that share a common property, using the
- [on_configuration_change](https://docs.getdbt.com/reference/resource-configs/on_configuration_change.md): on_configuration_change - Read this in-depth guide to learn about configuration change monitoring in dbt.
- [on-run-start & on-run-end](https://docs.getdbt.com/reference/project-configs/on-run-start-on-run-end.md): Read this guide to understand the on-run-start and on-run-end configurations in dbt.
- [Oracle configurations](https://docs.getdbt.com/reference/resource-configs/oracle-configs.md): Use parallel hint
- [Other artifact files](https://docs.getdbt.com/reference/artifacts/other-artifacts.md): index.html
- [overrides](https://docs.getdbt.com/reference/resource-properties/overrides.md): The overrides property is deprecated in v1.10.
- [packages-install-path](https://docs.getdbt.com/reference/project-configs/packages-install-path.md): Definition
- [Parsing](https://docs.getdbt.com/reference/global-configs/parsing.md): Partial Parsing
- [persist_docs](https://docs.getdbt.com/reference/resource-configs/persist_docs.md): Persist_docs - Read this in-depth guide to learn about configurations in dbt.
- [Platform-specific configs](https://docs.getdbt.com/reference/resource-configs/resource-configs.md): Platform-specific configs are used to configure the dbt project for a specific database platform.
- [Platform-specific data types](https://docs.getdbt.com/reference/resource-properties/data-types.md): Unit tests are designed to test for the expected values, not for the data types themselves. dbt takes the value you provide and attempts to cast it to the data type as inferred from the input and output models.
- [Postgres configurations](https://docs.getdbt.com/reference/resource-configs/postgres-configs.md): Postgres Configurations - Read this in-depth guide to learn about configurations in dbt.
- [Postgres Permissions](https://docs.getdbt.com/reference/database-permissions/postgres-permissions.md): In Postgres, permissions are used to control who can perform certain actions on different database objects. Use SQL statements to manage permissions in a Postgres database.
- [pre-hook & post-hook](https://docs.getdbt.com/reference/resource-configs/pre-hook-post-hook.md): Configure hooks to execute SQL before (pre) and after (post) a model is run in dbt.
- [Print output](https://docs.getdbt.com/reference/global-configs/print-output.md): Suppress print() messages in stdout
- [profile](https://docs.getdbt.com/reference/project-configs/profile.md): Read this guide to understand the profile configuration in dbt.
- [Programmatic invocations](https://docs.getdbt.com/reference/programmatic-invocations.md): In v1.5,  added support for programmatic invocations. The intent is to expose the existing  CLI via a Python entry point, such that top-level commands are callable from within a Python script or application.
- [Project flags](https://docs.getdbt.com/reference/global-configs/project-flags.md): Reference the table of all flags to see which global configs are available for setting in dbtproject.yml.
- [Project Parsing](https://docs.getdbt.com/reference/parsing.md): Read this guide to understand the project parsing configuration in dbt.
- [Putting it together](https://docs.getdbt.com/reference/node-selection/putting-it-together.md): This can get complex! Let's say I want a nightly run of models that build off snowplow data
- [query-comment](https://docs.getdbt.com/reference/project-configs/query-comment.md): The query-comment configuration also accepts a dictionary input, like so:
- [quote_columns](https://docs.getdbt.com/reference/resource-configs/quote_columns.md): Quote_columns - Read this in-depth guide to learn about configurations in dbt.
- [Record timing info](https://docs.getdbt.com/reference/global-configs/record-timing-info.md): The -r or --record-timing-info flag saves performance profiling information to a file. This file can be visualized with snakeviz to understand the performance characteristics of a dbt invocation.
- [Redshift configurations](https://docs.getdbt.com/reference/resource-configs/redshift-configs.md): Redshift Configurations - Read this in-depth guide to learn about configurations in dbt.
- [Redshift permissions](https://docs.getdbt.com/reference/database-permissions/redshift-permissions.md): In Redshift, permissions are used to control who can perform certain actions on different database objects. Use SQL statements to manage permissions in a Redshift database.
- [require-dbt-version](https://docs.getdbt.com/reference/project-configs/require-dbt-version.md): Read this guide to understand the require-dbt-version configuration in dbt.
- [Resource path](https://docs.getdbt.com/reference/resource-configs/resource-path.md): Learn how to use resource paths to configure resource types in dbt.
- [Resource type](https://docs.getdbt.com/reference/global-configs/resource-type.md): The --resource-type and --exclude-resource-type flags include or exclude resource types from the dbt build, dbt test, dbt clone, and dbt list commands.
- [resource-configs](https://docs.getdbt.com/reference/resource-configs.md)
- [returns](https://docs.getdbt.com/reference/resource-properties/returns.md): .yml'>
- [Run results JSON file](https://docs.getdbt.com/reference/artifacts/run-results-json.md): Current schema: v6
- [Salesforce Data Cloud configurations](https://docs.getdbt.com/reference/resource-configs/data-cloud-configs.md): Salesforce Data Cloud Configurations - Read this in-depth guide to learn about configurations in dbt.
- [schema](https://docs.getdbt.com/reference/resource-configs/schema.md): Override the default schema when dbt creates resources in your data platform.
- [Seed configurations](https://docs.getdbt.com/reference/seed-configs.md): Read this guide to learn about using seed configurations in dbt.
- [Seed properties](https://docs.getdbt.com/reference/seed-properties.md): Seed properties can be declared in .yml files under a seed key.
- [seed-paths](https://docs.getdbt.com/reference/project-configs/seed-paths.md): Definition
- [Semantic manifest](https://docs.getdbt.com/reference/artifacts/sl-manifest.md): Learn about the semantic manifest.json file and how you can use artifacts to gain insights about your dbt Semantic Layer.
- [Set operators](https://docs.getdbt.com/reference/node-selection/set-operators.md): Unions
- [severity, error_if, and warn_if](https://docs.getdbt.com/reference/resource-configs/severity.md): You can use error thresholds to configure the severity of test results and set when to produce an error or warning based on the number of failed tests.
- [SingleStore configurations](https://docs.getdbt.com/reference/resource-configs/singlestore-configs.md): Incremental materialization strategies
- [Snapshot configurations](https://docs.getdbt.com/reference/snapshot-configs.md): Read this guide to learn about using snapshot configurations in dbt.
- [Snapshot properties](https://docs.getdbt.com/reference/snapshot-properties.md): Read this guide to learn about using source properties in dbt.
- [snapshot_meta_column_names](https://docs.getdbt.com/reference/resource-configs/snapshot_meta_column_names.md): Snapshot meta column names
- [snapshot_name](https://docs.getdbt.com/reference/resource-configs/snapshot_name.md): Snapshot-name - Read this in-depth guide to learn about configurations in dbt.
- [snapshot-paths](https://docs.getdbt.com/reference/project-configs/snapshot-paths.md): Read this guide to understand the snapshot-paths configuration in dbt.
- [Snowflake adapter behavior changes](https://docs.getdbt.com/reference/global-configs/snowflake-changes.md): The enabletruthynullsequalsmacro flag
- [Snowflake configurations](https://docs.getdbt.com/reference/resource-configs/snowflake-configs.md): Snowflake Configurations - Read this in-depth guide to learn about configurations in dbt.
- [Snowflake permissions](https://docs.getdbt.com/reference/database-permissions/snowflake-permissions.md): In Snowflake, permissions are used to control who can perform certain actions on different database objects. Use SQL statements to manage permissions in a Snowflake database.
- [Source configurations](https://docs.getdbt.com/reference/source-configs.md): Learn how to use source configurations in dbt.
- [Source properties](https://docs.getdbt.com/reference/source-properties.md): Learn how to use source properties in dbt.
- [Sources JSON file](https://docs.getdbt.com/reference/artifacts/sources-json.md): Current schema: v3
- [sql_header](https://docs.getdbt.com/reference/resource-configs/sql_header.md): Sql_header - Read this in-depth guide to learn about configurations in dbt.
- [Starburst/Trino configurations](https://docs.getdbt.com/reference/resource-configs/trino-configs.md): Cluster requirements
- [Starrocks configurations](https://docs.getdbt.com/reference/resource-configs/starrocks-configs.md): Starrocks Configurations - Read this in-depth guide to learn about configurations in dbt.
- [Static analysis](https://docs.getdbt.com/reference/global-configs/static-analysis-flag.md): Use the --static-analysis flag to override model-level static_analysis behavior for a single run.
- [static_analysis](https://docs.getdbt.com/reference/resource-configs/static-analysis.md): Use static_analysis config to control how the Fusion engine performs static SQL analysis for models.
- [store_failures](https://docs.getdbt.com/reference/resource-configs/store_failures.md): The configured test(s) will store their failures when dbt test --store-failures is invoked. If you set this configuration as false but storefailuresas is configured, it will be overridden.
- [store_failures_as](https://docs.getdbt.com/reference/resource-configs/store_failures_as.md): For the test resource type, storefailuresas is an optional config that specifies how test failures should be stored in the database. If storefailures is also configured, storefailuresas takes precedence.
- [strategy](https://docs.getdbt.com/reference/resource-configs/strategy.md): Strategy - Read this in-depth guide to learn about configurations in dbt.
- [Supported data formats for unit tests](https://docs.getdbt.com/reference/resource-properties/data-formats.md): Currently, mock data for unit testing in dbt supports three formats:
- [Syntax overview](https://docs.getdbt.com/reference/node-selection/syntax.md): Node selection syntax enables you to execute dbt commands for specific models and resources.
- [tags](https://docs.getdbt.com/reference/resource-configs/tags.md): Configure tags to label and organize your dbt models and resources.
- [target_database](https://docs.getdbt.com/reference/resource-configs/target_database.md): Target_database - Read this in-depth guide to learn about configurations in dbt.
- [target_schema](https://docs.getdbt.com/reference/resource-configs/target_schema.md): Target_schema - Read this in-depth guide to learn about configurations in dbt.
- [Teradata configurations](https://docs.getdbt.com/reference/resource-configs/teradata-configs.md): General
- [Test selection examples](https://docs.getdbt.com/reference/node-selection/test-selection-examples.md): Test selection works a little differently from other resource selection. This makes it very easy to:
- [test-paths](https://docs.getdbt.com/reference/project-configs/test-paths.md): Definition
- [type](https://docs.getdbt.com/reference/resource-properties/type.md): .yml'>
- [unique_key](https://docs.getdbt.com/reference/resource-configs/unique_key.md): Learn more about unique_key configurations in dbt.
- [Unit test overrides](https://docs.getdbt.com/reference/resource-properties/unit-test-overrides.md): When configuring your unit test, you can override the output of macros, project variables, or environment variables for a given unit test.
- [Unit testing versioned SQL models](https://docs.getdbt.com/reference/resource-properties/unit-testing-versions.md): If your model has multiple versions, the default unit test will run on all versions of your model. To specify version(s) of your model to unit test, use include or exclude for the desired versions in your model versions config:
- [updated_at](https://docs.getdbt.com/reference/resource-configs/updated_at.md): Updated_at - Read this in-depth guide to learn about configurations in dbt.
- [Upsolver configurations](https://docs.getdbt.com/reference/resource-configs/upsolver-configs.md): Upsolver Configurations - Read this in-depth guide to learn about configurations in dbt.
- [Using the + prefix](https://docs.getdbt.com/reference/resource-configs/plus-prefix.md): The + prefix helps disambiguate between resource paths and configs in dbt_project.yml files.
- [version](https://docs.getdbt.com/reference/project-configs/version.md): dbt projects have two distinct types of version tags. This field has a different meaning depending on its location.
- [versions](https://docs.getdbt.com/reference/resource-properties/versions.md): .yml'>
- [Vertica configurations](https://docs.getdbt.com/reference/resource-configs/vertica-configs.md): Configuration of Incremental Models
- [Warnings](https://docs.getdbt.com/reference/global-configs/warnings.md): Use --warn-error to promote all warnings to errors
- [where](https://docs.getdbt.com/reference/resource-configs/where.md): Definition
- [YAML Selectors](https://docs.getdbt.com/reference/node-selection/yaml-selectors.md): Write resource selectors in YAML, save them with a human-friendly name, and reference them using the --selector flag.
- [Yellowbrick configurations](https://docs.getdbt.com/reference/resource-configs/yellowbrick-configs.md): Yellowbrick Configurations: Read this in-depth guide to learn about configurations in dbt.

## Search

- [Search the documentation](https://docs.getdbt.com/search.md)

## Set up dbt

- [About dbt setup](https://docs.getdbt.com/docs/about-setup.md): About setup of dbt locally and on the dbt platform
- [About environments](https://docs.getdbt.com/docs/environments-in-dbt.md): In software engineering, environments are used to enable engineers to develop and test code without impacting the users of their software. Typically, there are two types of environments in dbt:
- [Run your dbt projects](https://docs.getdbt.com/docs/running-a-dbt-project/run-your-dbt-projects.md): You can run your dbt projects with  or :
- [Using threads](https://docs.getdbt.com/docs/running-a-dbt-project/using-threads.md): Understand what threads mean and how to use them.

### dbt Core and Fusion

- [About dbt installation](https://docs.getdbt.com/docs/about-dbt-install.md): Learn how to install dbt in local environments
- [dbt environments](https://docs.getdbt.com/docs/core/dbt-core-environments.md): dbt makes it easy to maintain separate production and development environments through the use of targets within a profile. A typical profile, when using dbt locally (for example, running from your command line), will have a target named dev and have this set as the default. This means that while making changes, your objects will be built in your development target without affecting production queries made by your end users. Once you are confident in your changes, you can deploy the code to production, by running your dbt project with a prod target.

#### Connect data platform

- [About dbt Core data platform connections](https://docs.getdbt.com/docs/core/connect-data-platform/about-core-connections.md): Information about data platform connections in dbt Core
- [About profiles.yml](https://docs.getdbt.com/docs/core/connect-data-platform/profiles.yml.md): The dbt profiles.yml file contains the connection details for your data warehouse.
- [AlloyDB setup](https://docs.getdbt.com/docs/core/connect-data-platform/alloydb-setup.md): Profile Configuration
- [Apache Spark setup](https://docs.getdbt.com/docs/core/connect-data-platform/spark-setup.md): Read this guide to learn about the Apache Spark warehouse setup in dbt.
- [Athena setup](https://docs.getdbt.com/docs/core/connect-data-platform/athena-setup.md): Read this guide to learn about the Athena warehouse setup in dbt.
- [AWS Glue setup](https://docs.getdbt.com/docs/core/connect-data-platform/glue-setup.md): Read this guide to learn about the AWS Glue warehouse setup in dbt.
- [BigQuery setup](https://docs.getdbt.com/docs/core/connect-data-platform/bigquery-setup.md): Read this guide to learn about the BigQuery warehouse setup in dbt.
- [ClickHouse setup](https://docs.getdbt.com/docs/core/connect-data-platform/clickhouse-setup.md): Read this guide to learn about the ClickHouse warehouse setup in dbt.
- [Cloudera Hive setup](https://docs.getdbt.com/docs/core/connect-data-platform/hive-setup.md): Read this guide to learn about the Cloudera Hive warehouse setup in dbt.
- [Cloudera Impala setup](https://docs.getdbt.com/docs/core/connect-data-platform/impala-setup.md): Read this guide to learn about the Cloudera Impala warehouse setup in dbt.
- [Connection profiles](https://docs.getdbt.com/docs/core/connect-data-platform/connection-profiles.md): Configure the connection profile for your dbt project.
- [CrateDB setup](https://docs.getdbt.com/docs/core/connect-data-platform/cratedb-setup.md): Read this guide to learn about the CrateDB data platform setup in dbt.
- [Databend Cloud setup](https://docs.getdbt.com/docs/core/connect-data-platform/databend-setup.md): Read this guide to learn about the Databend warehouse setup in dbt.
- [Databricks Lakebase setup](https://docs.getdbt.com/docs/core/connect-data-platform/lakebase-setup.md): Profile Configuration
- [Databricks setup](https://docs.getdbt.com/docs/core/connect-data-platform/databricks-setup.md): Read this guide to learn about the Databricks warehouse setup in dbt.
- [Decodable setup](https://docs.getdbt.com/docs/core/connect-data-platform/decodable-setup.md): Some core functionality may be limited. If you're interested in contributing, see the source code for the repository listed below.
- [Doris setup](https://docs.getdbt.com/docs/core/connect-data-platform/doris-setup.md): Read this guide to learn about the Doris warehouse setup in dbt.
- [Dremio setup](https://docs.getdbt.com/docs/core/connect-data-platform/dremio-setup.md): Read this guide to learn about the Dremio warehouse setup in dbt.
- [DuckDB setup](https://docs.getdbt.com/docs/core/connect-data-platform/duckdb-setup.md): Read this guide to learn about the DuckDB warehouse setup in dbt.
- [Exasol setup](https://docs.getdbt.com/docs/core/connect-data-platform/exasol-setup.md): Read this guide to learn about the Exasol warehouse setup in dbt.
- [Extrica Setup](https://docs.getdbt.com/docs/core/connect-data-platform/extrica-setup.md): Read this guide to learn about the Extrica Trino Query Engine setup in dbt.
- [Firebolt setup](https://docs.getdbt.com/docs/core/connect-data-platform/firebolt-setup.md): Read this guide to learn about the Firebolt warehouse setup in dbt.
- [Greenplum setup](https://docs.getdbt.com/docs/core/connect-data-platform/greenplum-setup.md): Read this guide to learn about the Greenplum warehouse setup in dbt.
- [IBM DB2 setup](https://docs.getdbt.com/docs/core/connect-data-platform/ibmdb2-setup.md): Read this guide to learn about the IBM DB2 warehouse setup in dbt.
- [IBM Netezza setup](https://docs.getdbt.com/docs/core/connect-data-platform/ibmnetezza-setup.md): Read this guide to learn about the IBM Netezza setup in dbt.
- [IBM watsonx.data Presto setup](https://docs.getdbt.com/docs/core/connect-data-platform/watsonx-presto-setup.md): Read this guide to learn about the IBM watsonx.data Presto setup in dbt.
- [IBM watsonx.data Spark setup](https://docs.getdbt.com/docs/core/connect-data-platform/watsonx-spark-setup.md): Read this guide to learn about the IBM watsonx.data Spark setup in dbt.
- [Infer setup](https://docs.getdbt.com/docs/core/connect-data-platform/infer-setup.md): Read this guide to learn about the Infer warehouse setup in dbt.
- [iomete setup](https://docs.getdbt.com/docs/core/connect-data-platform/iomete-setup.md): Read this guide to learn about the iomete warehouse setup in dbt.
- [Layer setup](https://docs.getdbt.com/docs/core/connect-data-platform/layer-setup.md): Read this guide to learn about the Layer warehouse setup in dbt.
- [Materialize setup](https://docs.getdbt.com/docs/core/connect-data-platform/materialize-setup.md): Read this guide to learn about the Materialize warehouse setup in dbt.
- [MaxCompute setup](https://docs.getdbt.com/docs/core/connect-data-platform/maxcompute-setup.md): Read this guide to learn about the MaxCompute setup in dbt.
- [Microsoft Azure Synapse Analytics setup](https://docs.getdbt.com/docs/core/connect-data-platform/azuresynapse-setup.md): Read this guide to learn about the Mircosoft Azure Synapse Analytics dedicated SQL pool setup in dbt.
- [Microsoft Fabric Data Warehouse setup](https://docs.getdbt.com/docs/core/connect-data-platform/fabric-setup.md): Read this guide to learn about the Microsoft Fabric Data Warehouse setup in dbt.
- [Microsoft Fabric Lakehouse setup](https://docs.getdbt.com/docs/core/connect-data-platform/fabricspark-setup.md): Read this guide to learn about the Microsoft Fabric spark setup for Lakehouse in dbt.
- [Microsoft SQL Server setup](https://docs.getdbt.com/docs/core/connect-data-platform/mssql-setup.md): Read this guide to learn about the Microsoft SQL Server warehouse setup in dbt.
- [MindsDB setup](https://docs.getdbt.com/docs/core/connect-data-platform/mindsdb-setup.md): The dbt-mindsdb package allows dbt to connect to MindsDB.
- [MySQL setup](https://docs.getdbt.com/docs/core/connect-data-platform/mysql-setup.md): Read this guide to learn about the MySQL warehouse setup in dbt.
- [Oracle setup](https://docs.getdbt.com/docs/core/connect-data-platform/oracle-setup.md): Read this guide to learn about the Oracle warehouse setup in dbt.
- [Postgres setup](https://docs.getdbt.com/docs/core/connect-data-platform/postgres-setup.md): Read this guide to learn about the Postgres warehouse setup in dbt.
- [Redshift setup](https://docs.getdbt.com/docs/core/connect-data-platform/redshift-setup.md): Read this guide to learn about the Redshift warehouse setup in dbt.
- [RisingWave setup](https://docs.getdbt.com/docs/core/connect-data-platform/risingwave-setup.md): Read this guide to learn about how to set up RisingWave in dbt.
- [Rockset setup](https://docs.getdbt.com/docs/core/connect-data-platform/rockset-setup.md): Read this guide to learn about the Rockset warehouse setup in dbt.
- [SingleStore setup](https://docs.getdbt.com/docs/core/connect-data-platform/singlestore-setup.md): Read this guide to learn about the SingleStore warehouse setup in dbt.
- [Snowflake setup](https://docs.getdbt.com/docs/core/connect-data-platform/snowflake-setup.md): Read this guide to learn about the Snowflake warehouse setup in dbt.
- [SQLite setup](https://docs.getdbt.com/docs/core/connect-data-platform/sqlite-setup.md): Read this guide to learn about the SQLite warehouse setup in dbt.
- [Starburst/Trino setup](https://docs.getdbt.com/docs/core/connect-data-platform/trino-setup.md): Read this guide to learn about the Starburst/Trino warehouse setup in dbt.
- [Starrocks setup](https://docs.getdbt.com/docs/core/connect-data-platform/starrocks-setup.md): Read this guide to learn about the Starrocks warehouse setup in dbt.
- [Teradata setup](https://docs.getdbt.com/docs/core/connect-data-platform/teradata-setup.md): Read this guide to learn about the Teradata warehouse setup in dbt.
- [TiDB setup](https://docs.getdbt.com/docs/core/connect-data-platform/tidb-setup.md): Read this guide to learn about the TiDB warehouse setup in dbt.
- [Upsolver setup](https://docs.getdbt.com/docs/core/connect-data-platform/upsolver-setup.md): Read this guide to learn how to configure Upsolver with dbt.
- [Vertica setup](https://docs.getdbt.com/docs/core/connect-data-platform/vertica-setup.md): If you're interested in contributing, check out the source code for each repository listed below.
- [YDB setup](https://docs.getdbt.com/docs/core/connect-data-platform/ydb-setup.md): Read this guide to learn how to configure YDB with dbt.
- [Yellowbrick setup](https://docs.getdbt.com/docs/core/connect-data-platform/yellowbrick-setup.md): Read this guide to learn about the Yellowbrick warehouse setup in dbt.

#### Install dbt Core

- [About dbt Core installation](https://docs.getdbt.com/docs/core/installation-overview.md): Install dbt Core locally to begin transforming your data.
- [Install from source](https://docs.getdbt.com/docs/core/source-install.md): You can install dbt Core from its GitHub code source.
- [Install with Docker](https://docs.getdbt.com/docs/core/docker-install.md): You can use Docker to install dbt and adapter plugins from the command line.
- [Install with pip](https://docs.getdbt.com/docs/core/pip-install.md): Install dbt Core and adapter plugins from the command line with pip.

#### Install dbt Fusion engine

- [About Fusion local installation Preview](https://docs.getdbt.com/docs/fusion/about-fusion-install.md): Install the Fusion engine locally to take data transformation to the next level.
- [Install Fusion from the CLI Preview](https://docs.getdbt.com/docs/fusion/install-fusion-cli.md): Install the Fusion engine locally from the command line interface (CLI) to take data transformation to the next level.
- [Install the dbt VS Code extension Preview](https://docs.getdbt.com/docs/fusion/install-dbt-extension.md): Installation instructions for the dbt extension.

### dbt platform

- [Account integrations in dbt](https://docs.getdbt.com/docs/cloud/account-integrations.md): Learn how to configure account integrations for your dbt account.
- [Account settings in dbt](https://docs.getdbt.com/docs/cloud/account-settings.md): Learn how to enable account settings for your dbt users.
- [dbt environments](https://docs.getdbt.com/docs/dbt-cloud-environments.md): Learn about dbt's development environment to execute your project in the IDE
- [Multi-cell migration checklist](https://docs.getdbt.com/docs/cloud/migration.md): Prepare for account migration to AWS cell-based architecture.

#### Connect data platform

- [About data platform connections](https://docs.getdbt.com/docs/cloud/connect-data-platform/about-connections.md): Information about data platform connections
- [Connect Amazon Athena](https://docs.getdbt.com/docs/cloud/connect-data-platform/connect-amazon-athena.md): Configure the Amazon Athena data platform connection in dbt.
- [Connect Apache Spark](https://docs.getdbt.com/docs/cloud/connect-data-platform/connect-apache-spark.md): Setup instructions for connecting Apache Spark to dbt
- [Connect Azure Synapse Analytics](https://docs.getdbt.com/docs/cloud/connect-data-platform/connect-azure-synapse-analytics.md): Configure Azure Synapse Analytics connection.
- [Connect BigQuery](https://docs.getdbt.com/docs/cloud/connect-data-platform/connect-bigquery.md): Configure BigQuery connection.
- [Connect Databricks](https://docs.getdbt.com/docs/cloud/connect-data-platform/connect-databricks.md): Setup instructions for connecting Databricks to dbt
- [Connect Microsoft Fabric](https://docs.getdbt.com/docs/cloud/connect-data-platform/connect-microsoft-fabric.md): Configure Microsoft Fabric connection.
- [Connect Onehouse](https://docs.getdbt.com/docs/cloud/connect-data-platform/connect-onehouse.md): Setup instructions for connecting Onehouse to dbt
- [Connect PostgreSQL, Lakebase and AlloyDB](https://docs.getdbt.com/docs/cloud/connect-data-platform/connect-postgresql-alloydb.md): Setup instructions for connecting PostgreSQL, Lakebase, and AlloyDB to dbt
- [Connect Redshift](https://docs.getdbt.com/docs/cloud/connect-data-platform/connect-redshift.md): Setup instructions for connecting Redshift to dbt
- [Connect Snowflake](https://docs.getdbt.com/docs/cloud/connect-data-platform/connect-snowflake.md): Configure Snowflake connection.
- [Connect Starburst or Trino](https://docs.getdbt.com/docs/cloud/connect-data-platform/connect-starburst-trino.md): Configure Starburst or Trino connection.
- [Connect Teradata Preview](https://docs.getdbt.com/docs/cloud/connect-data-platform/connect-teradata.md): Configure the Teradata platform connection in dbt.

#### Git

- [About git](https://docs.getdbt.com/docs/cloud/git/git-version-control.md): Git overview
- [Authenticate with Azure DevOps](https://docs.getdbt.com/docs/cloud/git/authenticate-azure.md): dbt developers need to authenticate with Azure DevOps.
- [Configure Git in dbt](https://docs.getdbt.com/docs/cloud/git/git-configuration-in-dbt-cloud.md): Learn about the Git providers supported in dbt
- [Connect to Azure DevOps EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/git/connect-azure-devops.md): About Azure DevOps and dbt
- [Connect to GitHub](https://docs.getdbt.com/docs/cloud/git/connect-github.md): Learn how connecting your GitHub account provides convenience and another layer of security to dbt.
- [Connect to GitLab](https://docs.getdbt.com/docs/cloud/git/connect-gitlab.md): Learn how connecting your GitLab account provides convenience and another layer of security to dbt.
- [Connect with Git clone](https://docs.getdbt.com/docs/cloud/git/import-a-project-by-git-url.md): Learn how to connect to a git repository using a git URL.
- [Connect with managed repository](https://docs.getdbt.com/docs/cloud/git/managed-repository.md): Learn how to set up a project with a managed repository.
- [Merge conflicts](https://docs.getdbt.com/docs/cloud/git/merge-conflicts.md): Merge conflicts in the  often occur when multiple users are simultaneously making edits to the same section in the same file. This makes it difficult for  to decide what changes to incorporate in the final merge.
- [PR template](https://docs.getdbt.com/docs/cloud/git/pr-template.md): Configure pull request (PR) template URLs
- [Set up Azure DevOps EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/git/setup-service-principal.md): You can set up your Azure DevOps by creating a Microsoft Entra ID app and adding it to dbt.
- [Set up Azure DevOps with Service User](https://docs.getdbt.com/docs/cloud/git/setup-service-user.md): You can set up your Azure DevOps by creating a Microsoft Entra ID app and adding it to dbt.
- [Version control basics](https://docs.getdbt.com/docs/cloud/git/version-control-basics.md): Leverage Git to version control your code.

#### Manage access

- [About environment-level permissions](https://docs.getdbt.com/docs/cloud/manage-access/environment-permissions.md): About environment-level permissions to protect your information
- [About user access](https://docs.getdbt.com/docs/cloud/manage-access/about-user-access.md): Learn how dbt administrators can use dbt's permissioning model to control user-level access in a dbt account.
- [dbt audit log EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/manage-access/audit-log.md): You can troubleshoot possible issues and provide security audits by reviewing event activity in your organization.
- [Enterprise permissions EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/manage-access/enterprise-permissions.md): Permission sets for Enterprise plans.
- [Invite users to dbt](https://docs.getdbt.com/docs/cloud/manage-access/invite-users.md): Learn how to manually invite users to dbt
- [Migrating to Auth0 for SSO EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/manage-access/auth0-migration.md): Required actions for migrating to Auth0 for SSO services on dbt.
- [Multi-factor authentication](https://docs.getdbt.com/docs/cloud/manage-access/mfa.md): Configure dbt MFA
- [Self-service Starter account permissions](https://docs.getdbt.com/docs/cloud/manage-access/self-service-permissions.md): Learn how dbt administrators can use self-service permissions to control access in a dbt Starter account.
- [Set up BigQuery OAuth EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/manage-access/set-up-bigquery-oauth.md): Learn how dbt administrators can use BigQuery OAuth to control access in a dbt account
- [Set up Databricks OAuth EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/manage-access/set-up-databricks-oauth.md): Learn how dbt administrators can use Databricks OAuth to control access in a dbt account.
- [Set up environment-level permissions](https://docs.getdbt.com/docs/cloud/manage-access/environment-permissions-setup.md): Set up environment-level permissions to protect your information
- [Set up external OAuth with Redshift EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/manage-access/redshift-external-oauth.md): Configuration instructions for dbt and external OAuth connections with Redshift
- [Set up external OAuth with Snowflake EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/manage-access/snowflake-external-oauth.md): Configuration instructions for dbt and external OAuth connections with Snowflake
- [Set up SCIM EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/manage-access/scim.md): Configure SCIM for SSO
- [Set up Snowflake OAuth EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/manage-access/set-up-snowflake-oauth.md): Learn how dbt administrators can use Snowflake OAuth to control access in a dbt account.
- [Set up SSO with Google Workspace EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/manage-access/set-up-sso-google-workspace.md): Learn how dbt administrators can use Single-Sign On (SSO) via Google GSuite to control access in a dbt account.
- [Set up SSO with Microsoft Entra ID EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/manage-access/set-up-sso-microsoft-entra-id.md): Learn how dbt administrators can use Microsoft Entra ID to control access in a dbt account.
- [Set up SSO with Okta EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/manage-access/set-up-sso-okta.md): Enterprise-tier plans support single-sign on via Okta (using SAML). Currently supported features include:
- [Set up SSO with SAML 2.0 EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/manage-access/set-up-sso-saml-2.0.md): Enterprise-tier plans support single-sign on (SSO) for any SAML 2.0-compliant identity provider (IdP).
- [Single sign-on (SSO) overview EnterpriseEnterprise +](https://docs.getdbt.com/docs/cloud/manage-access/sso-overview.md): This overview explains how users are provisioned in  via Single Sign-On (SSO).
- [Users and licenses](https://docs.getdbt.com/docs/cloud/manage-access/seats-and-users.md): Learn how dbt administrators can use licenses and seats to control access in a dbt account.

#### Secure

- [About private connectivity](https://docs.getdbt.com/docs/cloud/secure/about-private-connectivity.md): Configuring private connections
- [Configure AWS PrivateLink for Postgres Enterprise +](https://docs.getdbt.com/docs/cloud/secure/postgres-privatelink.md): Configuring PrivateLink for Postgres
- [Configure AWS PrivateLink for Redshift Enterprise +](https://docs.getdbt.com/docs/cloud/secure/redshift-privatelink.md): Configuring PrivateLink for Redshift
- [Configuring BigQuery Private Service Connect Enterprise +](https://docs.getdbt.com/docs/cloud/secure/bigquery-psc.md): Configuring GCP Private Service Connect for BigQuery
- [Configuring Databricks and Azure Private Link](https://docs.getdbt.com/docs/cloud/secure/databricks-private-link.md): Configuring Azure Private Link for Databricks
- [Configuring Databricks PrivateLink Enterprise +](https://docs.getdbt.com/docs/cloud/secure/databricks-privatelink.md): Configuring AWS PrivateLink for Databricks
- [Configuring IP restrictions Enterprise +](https://docs.getdbt.com/docs/cloud/secure/ip-restrictions.md): Configuring IP restrictions to outside traffic from accessing your dbt environment
- [Configuring Private Link for Azure Database for Postgres Flexible Server](https://docs.getdbt.com/docs/cloud/secure/az-postgres-private-link.md): Configuring Private Link for Azure Database for Postgres Flexible Server
- [Configuring Private Link for Azure Synapse](https://docs.getdbt.com/docs/cloud/secure/az-synapse-private-link.md): Configuring Private Link for Azure Synapse
- [Configuring PrivateLink for self-hosted cloud VCS Enterprise +](https://docs.getdbt.com/docs/cloud/secure/vcs-privatelink.md): Setting up a PrivateLink connection between dbt and an organization’s cloud hosted git server
- [Configuring Snowflake and Azure Private Link](https://docs.getdbt.com/docs/cloud/secure/snowflake-private-link.md): Configuring Azure Private Link for Snowflake
- [Configuring Snowflake Private Service Connect Enterprise +](https://docs.getdbt.com/docs/cloud/secure/snowflake-psc.md): Configuring GCP Private Service Connect for Snowflake
- [Configuring Snowflake PrivateLink Enterprise +](https://docs.getdbt.com/docs/cloud/secure/snowflake-privatelink.md): Configuring AWS PrivateLink for Snowflake
- [Secure your tenant](https://docs.getdbt.com/docs/cloud/secure/secure-your-tenant.md): Learn how to secure your tenant for dbt

## Sql Reference

- [SQL AND](https://docs.getdbt.com/sql-reference/and.md): The AND operator returns results that meet all requirements passed into it. You’ll often see the AND operator used in a WHERE clause to filter query results.
- [SQL ANY and ALL](https://docs.getdbt.com/sql-reference/any-all.md): The ANY operator will return true if any of the conditions passed into evaluate to true, while ALL will only return true if all conditions passed into it are true.
- [SQL ARRAY_AGG](https://docs.getdbt.com/sql-reference/array-agg.md): The ARRAY_AGG function allows you to create an array of multiple data values in SQL.
- [SQL AVG](https://docs.getdbt.com/sql-reference/avg.md): The AVG function is used to calculate the simple average of a numeric column, but you may also see it used in a window function to calculate rolling averages.
- [SQL BETWEEN](https://docs.getdbt.com/sql-reference/between.md): The SQL BETWEEN condition allows you to specify a range of numerical, date-type, or text values to filter rows on in a query.
- [SQL CASE WHEN](https://docs.getdbt.com/sql-reference/case.md): CASE statements allow you to cascade through multiple scenarios (or cases) in your data, evaluate them if they’re true, and output a corresponding value for each case.
- [SQL CAST](https://docs.getdbt.com/sql-reference/cast.md): Executing the CAST function in a SELECT statement will return the column you specified as the newly specified data type.
- [SQL Comments](https://docs.getdbt.com/sql-reference/comments.md): Inline SQL comments will begin with two dashes (--) in front of them in a query or dbt model; any text following these dashes is therefore what you’d call “commented out.” For longer, multi-line comments, you’ll typically see this syntax `/* your multi-line comment here */` used.
- [SQL CONCAT](https://docs.getdbt.com/sql-reference/concat.md): The CONCAT function allows analytics engineers to join multiple string values in a query.
- [SQL COUNT](https://docs.getdbt.com/sql-reference/count.md): COUNT is an aggregate function that is used to return the count of rows of a specified field or all rows in a dataset. It is commonly used to get baseline statistical information of a dataset, help ensure primary keys are unique, and calculate business metrics.
- [SQL CROSS JOIN](https://docs.getdbt.com/sql-reference/cross-join.md): A cross join typically takes two columns between two database objects and creates a table forming a combination of all rows across joined tables, called a cartesian product.
- [SQL Data Types](https://docs.getdbt.com/sql-reference/data-types.md): The different data types in SQL are numeric, string, date, booleans, and semi-structured. This content covers the differences between them and their subcategories.
- [SQL DATE_PART](https://docs.getdbt.com/sql-reference/datepart.md): The DATE_PART function allows you to extract a specified date part from a date/time. Like most other SQL functions, you need to pass in arguments; for the DATE_PART function, you’ll pass in a date/timestamp/date field that you want to extract a date part from and specify the part you want removed.
- [SQL DATE_TRUNC](https://docs.getdbt.com/sql-reference/date-trunc.md): The DATE_TRUNC function will truncate a date or time to the first instance of a given date part. You can truncate to the weeks, months, years, or other date parts for a date or time field.
- [SQL DATEADD](https://docs.getdbt.com/sql-reference/dateadd.md): The DATEADD function in SQL adds a time/date interval to a date and then returns the date. This allows you to add or subtract a certain period of time from a given start date.
- [SQL DATEDIFF](https://docs.getdbt.com/sql-reference/datediff.md): The DATEDIFF function will return the difference in specified units (ex. days, weeks, years) between a start date/time and an end date/time.
- [SQL DISTINCT](https://docs.getdbt.com/sql-reference/distinct.md): Using DISTINCT in a SELECT statement will force a query to only return non-duplicate rows. You may commonly see a DISTINCT clause in COUNT functions to get counts of distinct rows.
- [SQL FROM](https://docs.getdbt.com/sql-reference/from.md): The SQL FROM statement allows you to identify  the database schema object (table/view) you want to select data from in a query.
- [SQL GROUP BY](https://docs.getdbt.com/sql-reference/group-by.md): The GROUP BY statement allows you to group query results by specified columns and is used in pair with aggregate functions such as AVG and SUM to calculate those values across specific rows.
- [SQL HAVING](https://docs.getdbt.com/sql-reference/having.md): Read this guide to learn about the SQL HAVING clause in dbt.
- [SQL ILIKE](https://docs.getdbt.com/sql-reference/ilike.md): The ILIKE operator helps you easily match, find, and filter out case-insensitive string values of a specified pattern by using SQL wildcards.
- [SQL IN](https://docs.getdbt.com/sql-reference/in.md): Read this guide to learn about the SQL IN operator in dbt.
- [SQL INNER JOINS](https://docs.getdbt.com/sql-reference/inner-join.md): An inner join between two database objects returns all rows that have matching join keys; any keys that don’t match are omitted from the query result.
- [SQL LEFT JOIN](https://docs.getdbt.com/sql-reference/left-join.md): The left join returns all rows in the FROM statement, regardless of match in the left join database object.
- [SQL LIKE](https://docs.getdbt.com/sql-reference/like.md): The LIKE operator helps you easily match, find, and filter out case-sensitive string values of a specified pattern by using SQL wildcards.
- [SQL LIMIT](https://docs.getdbt.com/sql-reference/limit.md): Read this guide to learn about the SQL LIMIT clause in dbt.
- [SQL LOWER](https://docs.getdbt.com/sql-reference/lower.md): Using the LOWER function on a string value will return the input as an all-lowercase string. It’s an effective way to create consistent capitalization for string values across your data.
- [SQL MAX](https://docs.getdbt.com/sql-reference/max.md): The SQL MAX aggregate function allows you to compute the maximum value from a column.
- [SQL MIN](https://docs.getdbt.com/sql-reference/min.md): The MIN aggregate function allows you to compute the minimum value from a column or across a set of rows for a column.
- [SQL NOT](https://docs.getdbt.com/sql-reference/not.md): The SQL NOT operator allows you to return results from conditions that are not true. he NOT boolean is kind of similar to an adjective—it’s often put in front of another operator.
- [SQL OR](https://docs.getdbt.com/sql-reference/or.md): Read this guide to learn about the SQL OR operator in dbt.
- [SQL ORDER BY](https://docs.getdbt.com/sql-reference/order-by.md): Read this guide to learn about the SQL ORDER BY clause in dbt.
- [SQL OUTER JOIN](https://docs.getdbt.com/sql-reference/outer-join.md): A SQL full outer join is a join between two tables that returns all rows from both tables, regardless of join key match success.
- [SQL RANK](https://docs.getdbt.com/sql-reference/rank.md): The RANK function returns the rank of a value (starting at 1) in an ordered group or dataset.
- [SQL Reference](https://docs.getdbt.com/sql-reference.md): The SQL Reference is a collection of SQL functions and keywords that you can use during your daily data work.
- [SQL RIGHT JOIN](https://docs.getdbt.com/sql-reference/right-join.md): Right joins return all rows in the right join database object regardless of match in the database object in the FROM statement.
- [SQL ROUND](https://docs.getdbt.com/sql-reference/round.md): The ROUND aggregate function allows you to round numeric fields or values in SQL to the number of decimal places of your choosing.
- [SQL ROW_NUMBER](https://docs.getdbt.com/sql-reference/row-number.md): The ROW_NUMBER function returns the unique row number of a row in an ordered group or dataset.
- [SQL SELECT](https://docs.getdbt.com/sql-reference/select.md): The SQL SELECT statement is the fundamental building block of any query that allows you to select specific columns from a database schema object.
- [SQL SELF JOINS](https://docs.getdbt.com/sql-reference/self-join.md): A self join allows you to join a dataset back onto itself. A common use cases to leverage a self join is when a table contains a foreign key to the primary key of that same table.
- [SQL Strings](https://docs.getdbt.com/sql-reference/strings.md): Strings in SQL are words or combination of characters that you’ll typically see encased in single quotes (ex. 'Jaffle Shop', '1234 Shire Lane', 'Plan A').
- [SQL SUM](https://docs.getdbt.com/sql-reference/sum.md): The SUM aggregate function allows you to calculate the sum of a numeric column or across a set of rows for a column.
- [SQL TRIM](https://docs.getdbt.com/sql-reference/trim.md): The SQL TRIM function removes the leading and trailing characters of a string. By default, it removes the blank space character from the beginning and end of a string.
- [SQL UPPER](https://docs.getdbt.com/sql-reference/upper.md): Using the UPPER function on a string value will return the input as an all-uppercase string. It’s an effective way to create expected capitalization for certain string values across your data.
- [SQL WHERE](https://docs.getdbt.com/sql-reference/where.md): Read this guide to learn about the SQL WHERE clause in dbt.

## Tags

- [17 docs tagged with "Metrics"](https://docs.getdbt.com/tags/metrics.md)
- [19 docs tagged with "Quickstart"](https://docs.getdbt.com/tags/quickstart.md)
- [2 docs tagged with "analyst"](https://docs.getdbt.com/tags/analyst.md)
- [2 docs tagged with "API"](https://docs.getdbt.com/tags/api.md)
- [2 docs tagged with "CI"](https://docs.getdbt.com/tags/ci.md)
- [2 docs tagged with "dbt Fusion engine"](https://docs.getdbt.com/tags/dbt-fusion-engine.md)
- [2 docs tagged with "dbt Insights"](https://docs.getdbt.com/tags/dbt-insights.md)
- [2 docs tagged with "Redshift"](https://docs.getdbt.com/tags/redshift.md)
- [2 docs tagged with "SAO"](https://docs.getdbt.com/tags/sao.md)
- [2 docs tagged with "Troubleshooting"](https://docs.getdbt.com/tags/troubleshooting.md)
- [20 docs tagged with "dbt Core"](https://docs.getdbt.com/tags/dbt-core.md)
- [24 docs tagged with "dbt platform"](https://docs.getdbt.com/tags/dbt-platform.md)
- [3 docs tagged with "APIs"](https://docs.getdbt.com/tags/ap-is.md)
- [3 docs tagged with "BigQuery"](https://docs.getdbt.com/tags/big-query.md)
- [3 docs tagged with "IDE"](https://docs.getdbt.com/tags/ide.md)
- [3 docs tagged with "platform"](https://docs.getdbt.com/tags/platform.md)
- [39 docs tagged with "Semantic Layer"](https://docs.getdbt.com/tags/semantic-layer.md)
- [4 docs tagged with "dbt Fusion"](https://docs.getdbt.com/tags/dbt-fusion.md)
- [4 docs tagged with "Orchestration"](https://docs.getdbt.com/tags/orchestration.md)
- [5 docs tagged with "Snowflake"](https://docs.getdbt.com/tags/snowflake.md)
- [6 docs tagged with "Databricks"](https://docs.getdbt.com/tags/databricks.md)
- [6 docs tagged with "Migration"](https://docs.getdbt.com/tags/migration.md)
- [6 docs tagged with "Webhooks"](https://docs.getdbt.com/tags/webhooks.md)
- [9 docs tagged with "scheduler"](https://docs.getdbt.com/tags/scheduler.md)
- [One doc tagged with "Adapter creation"](https://docs.getdbt.com/tags/adapter-creation.md)
- [One doc tagged with "Amazon"](https://docs.getdbt.com/tags/amazon.md)
- [One doc tagged with "Athena"](https://docs.getdbt.com/tags/athena.md)
- [One doc tagged with "Best practices"](https://docs.getdbt.com/tags/best-practices.md)
- [One doc tagged with "BigFrames"](https://docs.getdbt.com/tags/big-frames.md)
- [One doc tagged with "Canvas"](https://docs.getdbt.com/tags/canvas.md)
- [One doc tagged with "Catalog"](https://docs.getdbt.com/tags/catalog.md)
- [One doc tagged with "cost savings"](https://docs.getdbt.com/tags/cost-savings.md)
- [One doc tagged with "dbt Cloud"](https://docs.getdbt.com/tags/dbt-cloud.md)
- [One doc tagged with "Dremio"](https://docs.getdbt.com/tags/dremio.md)
- [One doc tagged with "Explorer"](https://docs.getdbt.com/tags/explorer.md)
- [One doc tagged with "GCP"](https://docs.getdbt.com/tags/gcp.md)
- [One doc tagged with "Git"](https://docs.getdbt.com/tags/git.md)
- [One doc tagged with "Google"](https://docs.getdbt.com/tags/google.md)
- [One doc tagged with "Governance"](https://docs.getdbt.com/tags/governance.md)
- [One doc tagged with "Jan-1-2020"](https://docs.getdbt.com/tags/jan-1-2020.md)
- [One doc tagged with "Jan-1-2021"](https://docs.getdbt.com/tags/jan-1-2021.md)
- [One doc tagged with "Jinja"](https://docs.getdbt.com/tags/jinja.md)
- [One doc tagged with "model"](https://docs.getdbt.com/tags/model.md)
- [One doc tagged with "models built"](https://docs.getdbt.com/tags/models-built.md)
- [One doc tagged with "SQL"](https://docs.getdbt.com/tags/sql.md)
- [One doc tagged with "Teradata"](https://docs.getdbt.com/tags/teradata.md)
- [One doc tagged with "v0.5.0"](https://docs.getdbt.com/tags/v-0-5-0.md)
- [One doc tagged with "v1.1.01"](https://docs.getdbt.com/tags/v-1-1-01.md)
- [One doc tagged with "v1.1.02"](https://docs.getdbt.com/tags/v-1-1-02.md)
- [One doc tagged with "v1.1.03"](https://docs.getdbt.com/tags/v-1-1-03.md)
- [One doc tagged with "v1.1.04"](https://docs.getdbt.com/tags/v-1-1-04.md)
- [One doc tagged with "v1.1.05"](https://docs.getdbt.com/tags/v-1-1-05.md)
- [One doc tagged with "v1.1.06"](https://docs.getdbt.com/tags/v-1-1-06.md)
- [One doc tagged with "v1.1.07"](https://docs.getdbt.com/tags/v-1-1-07.md)
- [One doc tagged with "v1.1.08"](https://docs.getdbt.com/tags/v-1-1-08.md)
- [One doc tagged with "v1.1.09"](https://docs.getdbt.com/tags/v-1-1-09.md)
- [One doc tagged with "v1.1.10"](https://docs.getdbt.com/tags/v-1-1-10.md)
- [One doc tagged with "v1.1.11"](https://docs.getdbt.com/tags/v-1-1-11.md)
- [One doc tagged with "v1.1.12"](https://docs.getdbt.com/tags/v-1-1-12.md)
- [One doc tagged with "v1.1.13"](https://docs.getdbt.com/tags/v-1-1-13.md)
- [One doc tagged with "v1.1.14"](https://docs.getdbt.com/tags/v-1-1-14.md)
- [One doc tagged with "v1.1.15"](https://docs.getdbt.com/tags/v-1-1-15.md)
- [One doc tagged with "v1.1.16"](https://docs.getdbt.com/tags/v-1-1-16.md)
- [One doc tagged with "v1.1.18"](https://docs.getdbt.com/tags/v-1-1-18.md)
- [One doc tagged with "v1.1.19"](https://docs.getdbt.com/tags/v-1-1-19.md)
- [One doc tagged with "v1.1.20"](https://docs.getdbt.com/tags/v-1-1-20.md)
- [One doc tagged with "v1.1.21"](https://docs.getdbt.com/tags/v-1-1-21.md)
- [One doc tagged with "v1.1.22"](https://docs.getdbt.com/tags/v-1-1-22.md)
- [One doc tagged with "v1.1.23"](https://docs.getdbt.com/tags/v-1-1-23.md)
- [One doc tagged with "v1.1.24"](https://docs.getdbt.com/tags/v-1-1-24.md)
- [One doc tagged with "v1.1.25"](https://docs.getdbt.com/tags/v-1-1-25.md)
- [One doc tagged with "v1.1.26"](https://docs.getdbt.com/tags/v-1-1-26.md)
- [One doc tagged with "v1.1.27"](https://docs.getdbt.com/tags/v-1-1-27.md)
- [One doc tagged with "v1.1.28"](https://docs.getdbt.com/tags/v-1-1-28.md)
- [One doc tagged with "v1.1.29"](https://docs.getdbt.com/tags/v-1-1-29.md)
- [One doc tagged with "v1.1.30"](https://docs.getdbt.com/tags/v-1-1-30.md)
- [One doc tagged with "v1.1.31"](https://docs.getdbt.com/tags/v-1-1-31.md)
- [One doc tagged with "v1.1.32"](https://docs.getdbt.com/tags/v-1-1-32.md)
- [One doc tagged with "v1.1.33"](https://docs.getdbt.com/tags/v-1-1-33.md)
- [One doc tagged with "v1.1.34"](https://docs.getdbt.com/tags/v-1-1-34.md)
- [One doc tagged with "v1.1.35"](https://docs.getdbt.com/tags/v-1-1-35.md)
- [One doc tagged with "v1.1.36"](https://docs.getdbt.com/tags/v-1-1-36.md)
- [One doc tagged with "v1.1.37"](https://docs.getdbt.com/tags/v-1-1-37.md)
- [One doc tagged with "v1.1.38"](https://docs.getdbt.com/tags/v-1-1-38.md)
- [One doc tagged with "v1.1.39"](https://docs.getdbt.com/tags/v-1-1-39.md)
- [One doc tagged with "v1.1.40"](https://docs.getdbt.com/tags/v-1-1-40.md)
- [One doc tagged with "v1.1.41"](https://docs.getdbt.com/tags/v-1-1-41.md)
- [One doc tagged with "Visual Editor"](https://docs.getdbt.com/tags/visual-editor.md)
- [Tags](https://docs.getdbt.com/tags.md)

## Terms

- [hover-terms](https://docs.getdbt.com/terms/hover-terms.md)
